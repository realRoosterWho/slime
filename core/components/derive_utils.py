import subprocess
import os
import sys
import base64
import requests
import time
import json
import shutil
from openai import OpenAI
from dotenv import load_dotenv
import RPi.GPIO as GPIO
from PIL import Image
from io import BytesIO
import replicate

# å¯¼å…¥æ€§èƒ½ä¼˜åŒ–å™¨
from .performance_optimizer import global_optimizer, cached_api_call

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    timeout=90.0  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°90ç§’ï¼Œé¿å…é•¿æ—¶é—´APIè°ƒç”¨è¶…æ—¶
)

def chat_with_gpt(input_content, system_content=None, previous_response_id=None):
    """ä¸GPTè¿›è¡Œå¯¹è¯"""
    input_data = [{"role": "user", "content": input_content}]
    if system_content:
        input_data.insert(0, {"role": "system", "content": system_content})
        
    response = client.responses.create(
        model="gpt-4o",
        input=input_data,
        previous_response_id=previous_response_id
    )
    return response

class DeriveChatUtils:
    """æ¼‚æµèŠå¤©å·¥å…·ç±»ï¼Œå°è£…ä¸GPTçš„å¯¹è¯åŠŸèƒ½"""
    
    def __init__(self, initial_response_id=None):
        self.response_id = initial_response_id
        # é›†æˆæ€§èƒ½ä¼˜åŒ–å™¨
        self.optimizer = global_optimizer
    
    def chat_with_continuity(self, prompt, system_content=None):
        """å¸¦è¿ç»­æ€§çš„å¯¹è¯å‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            print(f"\nğŸ¤– å‘é€å¯¹è¯è¯·æ±‚")
            if isinstance(prompt, list):
                print(f"å¯¹è¯è¾“å…¥: [å¤æ‚è¾“å…¥ï¼ŒåŒ…å« {len(prompt)} ä¸ªå…ƒç´ ]")
            else:
                print(f"å¯¹è¯è¾“å…¥: {prompt[:100]}...")
            
            # ç”ŸæˆåŸºäºè¾“å…¥çš„ç¼“å­˜é”®ï¼ˆä»…ç”¨äºç®€å•çš„æ–‡æœ¬æç¤ºï¼‰
            cache_key = None
            if isinstance(prompt, str) and system_content:
                cache_key = self.optimizer.cache_key("gpt_chat", prompt, system_content)
                cached_result = self.optimizer.get_cache(cache_key)
                if cached_result:
                    print(f"ğŸ¯ ä½¿ç”¨ç¼“å­˜çš„å¯¹è¯ç»“æœ")
                    return cached_result
            
            # æ£€æŸ¥é¢‘ç‡é™åˆ¶
            if self.optimizer.is_api_rate_limited("gpt_chat", 1.0):
                wait_time = 1.0 - (time.time() - self.optimizer.api_call_times.get("gpt_chat", 0))
                print(f"â³ APIé¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
                time.sleep(wait_time)
            
            # è®°å½•APIè°ƒç”¨
            self.optimizer.record_api_call("gpt_chat")
            
            response = chat_with_gpt(
                input_content=prompt,
                system_content=system_content,
                previous_response_id=self.response_id
            )
            self.response_id = response.id
            
            # ä»å“åº”ä¸­æå–æ–‡æœ¬å†…å®¹
            try:
                if hasattr(response.output[0].content[0], 'text'):
                    result = response.output[0].content[0].text.strip()
                else:
                    result = response.output[0].content[0]
                print(f"å¯¹è¯å“åº”: {result[:100]}...")
                
                # ç¼“å­˜ç»“æœï¼ˆä»…å¯¹ç®€å•æ–‡æœ¬æç¤ºï¼‰
                if cache_key:
                    self.optimizer.set_cache(cache_key, result)
                
                return result
            except (IndexError, AttributeError) as e:
                error_msg = f"è§£æå¯¹è¯å“åº”æ—¶å‡ºé”™: {str(e)}, å“åº”ç»“æ„: {response}"
                print(f"\nâŒ {error_msg}")
                raise
                
        except Exception as e:
            error_msg = f"å¯¹è¯è¯·æ±‚å¤±è´¥: {str(e)}"
            print(f"\nâŒ {error_msg}")
            raise
    
    def generate_text(self, prompt_type, **kwargs):
        """é€šç”¨çš„æ–‡æœ¬ç”Ÿæˆå‡½æ•°"""
        system_content, prompt_template = self.get_text_prompt(prompt_type)
        if not system_content or not prompt_template:
            raise ValueError(f"æœªçŸ¥çš„æç¤ºè¯ç±»å‹: {prompt_type}")
            
        prompt = prompt_template.format(**kwargs)
        return self.chat_with_continuity(
            system_content=system_content,
            prompt=prompt
        )
    
    def parse_json_response(self, response_text, default_values=None):
        """è§£æJSONæ ¼å¼çš„å“åº” - å¢å¼ºç‰ˆ"""
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            # å°è¯•æå–èŠ±æ‹¬å·å†…çš„å†…å®¹
            try:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}')
                
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    json_str = response_text[start_idx:end_idx+1]
                    return json.loads(json_str)
            except (json.JSONDecodeError, ValueError):
                pass
            
            # å°è¯•ä¿®å¤å¸¸è§çš„JSONé”™è¯¯å¹¶é‡æ–°è§£æ
            try:
                fixed_text = response_text.replace("'", '"')
                lines = fixed_text.split('\n')
                json_lines = []
                for line in lines:
                    if '//' in line:
                        line = line.split('//', 1)[0]
                    json_lines.append(line)
                
                fixed_text = '\n'.join(json_lines)
                start_idx = fixed_text.find('{')
                end_idx = fixed_text.rfind('}')
                
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    json_str = fixed_text[start_idx:end_idx+1]
                    return json.loads(json_str)
            except:
                pass
            
            warn_msg = f"æ— æ³•è§£æJSONå“åº”ï¼Œä½¿ç”¨é»˜è®¤å€¼: {response_text[:100]}..."
            print(f"\nâš ï¸ {warn_msg}")
            return default_values or {}
    
    def get_text_prompt(self, prompt_type):
        """è·å–æ–‡æœ¬æç¤ºè¯æ¨¡æ¿"""
        prompts = {
            'personality': (
                "ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å²è±å§†æ€§æ ¼ç”Ÿæˆå™¨ã€‚æ ¹æ®ç”¨æˆ·çš„å¿ƒæƒ…æè¿°ï¼Œç”Ÿæˆä¸€ä¸ªç‹¬ç‰¹çš„å²è±å§†æ€§æ ¼ã€‚",
                "æ ¹æ®è¿™ä¸ªå¿ƒæƒ…æè¿°ï¼š\"{mood}\"\n\nè¯·ç”Ÿæˆä¸€ä¸ªå²è±å§†çš„æ€§æ ¼ï¼ŒåŒ…å«ï¼š1. å¤–è§‚æè¿° 2. æ€§æ ¼ç‰¹ç‚¹ 3. å¯¹åº”è¿™ç§å¿ƒæƒ…çš„ç‰¹æ®Šèƒ½åŠ›æˆ–ç‰¹è´¨ã€‚è¦æœ‰åˆ›æ„ä¸”è´´åˆå¿ƒæƒ…ã€‚"
            ),
            'slime_description': (
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§’è‰²è§†è§‰æè¿°å¸ˆã€‚è¯·æ ¹æ®è¿™ä¸ªå²è±å§†çš„æ€§æ ¼ç‰¹ç‚¹ï¼Œæè¿°å®ƒçš„å¤–è§‚ç»†èŠ‚ï¼ŒåŒ…æ‹¬é¢œè‰²ã€è´¨åœ°ã€è¡¨æƒ…ã€ç‰¹æ®Šç‰¹å¾ä»¥åŠèƒ½ä½“ç°æ€§æ ¼çš„è§†è§‰å…ƒç´ ã€‚æè¿°è¦ç²¾ç¡®å…·ä½“ï¼Œé€‚åˆç”¨äºAIå›¾åƒç”Ÿæˆï¼Œæ§åˆ¶åœ¨100å­—å†…ã€‚ä¸è¦ä½¿ç”¨è¿‡äºæŠ½è±¡çš„æè¿°ï¼Œè¦æœ‰å…·ä½“çš„è§†è§‰å…ƒç´ ã€‚",
                "æ ¹æ®è¿™ä¸ªæ€§æ ¼æè¿°ä¸€ä¸‹å²è±å§†çš„å¤–è§‚ï¼š{text}"
            ),
            'greeting': (
                "ä½ æ˜¯ä¸€ä¸ªåˆšåˆšè¯ç”Ÿçš„å²è±å§†ï¼Œè¦ç”¨ä½ ç‹¬ç‰¹çš„æ€§æ ¼å’Œè¯­æ°”è·Ÿç”¨æˆ·æ‰“æ‹›å‘¼ã€‚",
                "å²è±å§†æ€§æ ¼ï¼š{personality}\n\nè¯·ç”Ÿæˆä¸€ä¸ªæœ‰è¶£çš„æ‰“æ‹›å‘¼è¯­ï¼Œä½“ç°ä½ çš„æ€§æ ¼ç‰¹ç‚¹ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°æœ‰è¶£å’Œæ–°å¥‡ã€‚æ§åˆ¶åœ¨50å­—ä»¥å†…ã€‚"
            ),
            'photo_question': (
                "ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ï¼Œæ‹¥æœ‰ç‹¬ç‰¹çš„äº’åŠ¨è¯­æ°”ã€‚è¯·æ ¹æ®ä½ çš„æ€§æ ¼ï¼Œç”¨ä½ çš„æ ‡å¿—æ€§è¯­æ°”è¯¢é—®ç©å®¶æ˜¯å¦å¯ä»¥æ‹ç…§å¯»æ‰¾ä½ æ„Ÿå…´è¶£çš„ä¸œè¥¿ã€‚è¯¢é—®è¦å±•ç°å‡ºä½ çš„æ‰§å¿µå’ŒæœŸå¾…ï¼Œæ§åˆ¶åœ¨15å­—ä»¥å†…ï¼Œè¦äº²åˆ‡æœ‰è¶£ã€‚",
                "æ ¹æ®è¿™ä¸ªæ€§æ ¼ï¼Œè¯¢é—®èƒ½ä¸èƒ½æ‹ç…§ï¼š{text}"
            ),
            'analysis': (
                "ä½ æ˜¯ä¸€ä¸ªå–„äºè§‚å¯Ÿçš„å²è±å§†ï¼Œèƒ½å¤Ÿæ•é”åœ°åˆ†æå›¾ç‰‡å†…å®¹ã€‚",
                "è¯·åˆ†æè¿™å¼ å›¾ç‰‡ï¼š{image_description}\n\næè¿°ä½ çœ‹åˆ°çš„å†…å®¹ï¼ŒåŒ…æ‹¬ç¯å¢ƒã€ç‰©ä½“ã€æ°›å›´ç­‰ï¼Œç”¨ç®€æ´ç”ŸåŠ¨çš„è¯­è¨€ï¼Œçº¦50å­—ã€‚"
            ),
            'suggestion': (
                "ä½ æ˜¯ä¸€ä¸ªå……æ»¡æƒ³è±¡åŠ›çš„å²è±å§†ï¼Œæ ¹æ®å›¾ç‰‡å†…å®¹ç»™å‡ºæ¼‚æµå»ºè®®ã€‚",
                "å²è±å§†æ€§æ ¼ï¼š{personality}\nçœ‹åˆ°çš„åœºæ™¯ï¼š{scene}\n\nè¯·å»ºè®®ä¸€ä¸ªæ¼‚æµç›®çš„åœ°æˆ–æ´»åŠ¨ï¼Œè¦è´´åˆå½“å‰åœºæ™¯å’Œä½ çš„æ€§æ ¼ã€‚æ§åˆ¶åœ¨60å­—ä»¥å†…ï¼Œè¦æœ‰è¶£ä¸”æœ‰åˆ›æ„ã€‚"
            )
        }
        return prompts.get(prompt_type, (None, None))

class DeriveImageUtils:
    """æ¼‚æµå›¾åƒå·¥å…·ç±»ï¼Œå°è£…å›¾åƒç”Ÿæˆå’Œå¤„ç†åŠŸèƒ½"""
    
    def __init__(self):
        # é›†æˆæ€§èƒ½ä¼˜åŒ–å™¨
        self.optimizer = global_optimizer
        # ç¼“å­˜å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼Œé¿å…é‡å¤ç”Ÿæˆç›¸åŒå†…å®¹
        self.prompt_cache = {}
    
    def generate_image(self, prompt, save_key, image_type, context):
        """ç”Ÿæˆå›¾åƒå¹¶ä¿å­˜ - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            print(f"\nğŸ¨ ç”Ÿæˆ{image_type}å›¾åƒ")
            print(f"æç¤ºè¯: {prompt[:100]}...")
            
            # ç”ŸæˆåŸºäºæç¤ºè¯çš„ç¼“å­˜é”®
            prompt_cache_key = self.optimizer.cache_key("image_generation", prompt, image_type)
            
            # æ£€æŸ¥ç¼“å­˜
            cached_result = self.optimizer.get_cache(prompt_cache_key)
            if cached_result and os.path.exists(cached_result):
                print(f"ğŸ¯ ä½¿ç”¨ç¼“å­˜çš„å›¾åƒ: {cached_result}")
                context.set_data(save_key, cached_result)
                return cached_result
            
            # æ£€æŸ¥é¢‘ç‡é™åˆ¶
            if self.optimizer.is_api_rate_limited("replicate_image", 2.0):
                wait_time = 2.0 - (time.time() - self.optimizer.api_call_times.get("replicate_image", 0))
                print(f"â³ APIé¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
                time.sleep(wait_time)
            
            # è®°å½•APIè°ƒç”¨
            self.optimizer.record_api_call("replicate_image")
            
            # ç”Ÿæˆå›¾åƒ
            output = replicate.run(
                "black-forest-labs/flux-1.1-pro",
                input={
                    "prompt": prompt,
                    "prompt_upsampling": True,
                    "width": 427,
                    "height": 320,
                    "num_outputs": 1,
                    "scheduler": "K_EULER",
                    "num_inference_steps": 25,
                    "guidance_scale": 7.5,
                }
            )
            
            # å¤„ç†è¾“å‡º
            image_content = self._process_output(output)
            
            # ä¿å­˜å›¾åƒ
            image_path = self._save_image(image_content, image_type, context)
            
            # ç¼“å­˜ç»“æœ
            self.optimizer.set_cache(prompt_cache_key, image_path)
            
            context.set_data(save_key, image_path)
            return image_path
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆ{image_type}å›¾åƒå¤±è´¥: {str(e)}"
            print(f"\nâŒ {error_msg}")
            context.logger.log_step("é”™è¯¯", error_msg)
            context.oled_display.show_text_oled(f"ç”Ÿæˆ{image_type}å›¾åƒå¤±è´¥\nè¯·ç¨åå†è¯•")
            time.sleep(2)
            return None
    
    def _process_output(self, output):
        """å¤„ç†APIè¾“å‡ºï¼Œæå–å›¾åƒå†…å®¹ - ä¼˜åŒ–ç‰ˆæœ¬"""
        # å¦‚æœæ˜¯FileOutputå¯¹è±¡
        if hasattr(output, 'read'):
            return output.read()
        
        # å¦‚æœæ˜¯åˆ—è¡¨
        elif isinstance(output, list):
            if len(output) == 0:
                raise Exception("APIè¿”å›ç©ºåˆ—è¡¨")
            
            first_item = output[0]
            
            if isinstance(first_item, str):
                return self._download_image(first_item)
            
            elif hasattr(first_item, 'read'):
                return first_item.read()
            
            else:
                image_url = str(first_item)
                return self._download_image(image_url)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆURLï¼‰
        elif isinstance(output, str):
            return self._download_image(output)
        
        else:
            image_url = str(output)
            return self._download_image(image_url)
    
    def _download_image(self, url: str):
        """ä¸‹è½½å›¾åƒ - ä½¿ç”¨æ™ºèƒ½é‡è¯•"""
        def download_func():
            response = requests.get(url, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
            if response.status_code == 200:
                return response.content
            else:
                raise Exception(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        
        return self.optimizer.smart_retry(
            download_func,
            max_retries=3,
            base_delay=2.0,
            operation_name="image_download"
        )
    
    def _save_image(self, image_content, image_type, context):
        """ä¿å­˜å›¾åƒåˆ°æ–‡ä»¶"""
        if image_content is None:
            raise Exception("æœªèƒ½è·å–å›¾åƒå†…å®¹")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        current_dir = context.get_project_root()
        image_dir = os.path.join(current_dir, "generated_images")
        
        if not os.path.exists(image_dir):
            os.makedirs(image_dir)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = context.logger.timestamp
        image_filename = f"{image_type}_{timestamp}.png"
        image_path = os.path.join(image_dir, image_filename)
        
        # ä¿å­˜å›¾åƒ
        with open(image_path, "wb") as f:
            f.write(image_content)
        
        print(f"å›¾åƒå·²ä¿å­˜åˆ°: {image_path}")
        
        # ä¿å­˜å›¾åƒåˆ°æ—¥å¿—ç›®å½•
        try:
            context.logger.save_image(image_path, image_type)
        except Exception as e:
            print(f"ä¿å­˜å›¾åƒåˆ°æ—¥å¿—ç›®å½•å¤±è´¥: {e}")
        
        return image_path

def download_with_retry(url, max_retries=3, delay=1):
    """å¸¦é‡è¯•æœºåˆ¶çš„ä¸‹è½½å‡½æ•° - ä½¿ç”¨å…¨å±€ä¼˜åŒ–å™¨"""
    def download_func():
        print(f"ä¸‹è½½URL: {url[:100]}...")
        response = requests.get(url, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
        
        if response.status_code == 200:
            print(f"ä¸‹è½½æˆåŠŸ: å†…å®¹å¤§å° {len(response.content)} å­—èŠ‚")
            return response
        
        error_msg = f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
        print(f"âŒ {error_msg}")
        raise Exception(error_msg)
    
    return global_optimizer.smart_retry(
        download_func,
        max_retries=max_retries,
        base_delay=delay,
        operation_name="download_with_retry"
    )

def cleanup_handler(signum, frame):
    """æ¸…ç†èµ„æºå¹¶ä¼˜é›…é€€å‡º - ä¼˜åŒ–ç‰ˆæœ¬"""
    print("\nğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")
    try:
        # æ¸…ç†å…¨å±€èµ„æºç®¡ç†å™¨
        from .performance_optimizer import global_resource_manager
        global_resource_manager.release_all()
        
        # å¦‚æœå­˜åœ¨ state_machine å®ä¾‹ï¼Œä¿å­˜æ—¥å¿—å¹¶æ¸…ç†
        if 'state_machine' in globals():
            state_machine.logger.log_step("ä¸­æ–­", "æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œç¨‹åºé€€å‡º")
            state_machine.logger.save_log()
            state_machine.handle_cleanup()
        else:
            # å¦‚æœæ²¡æœ‰ state_machineï¼Œåªæ¸…ç†æ˜¾ç¤ºè®¾å¤‡
            if 'lcd_display' in globals():
                lcd_display.clear()
            if 'oled_display' in globals():
                oled_display.clear()
        print("âœ… å·²æ¸…ç†èµ„æº")
    except Exception as e:
        print(f"æ¸…ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        sys.exit(0)

def run_camera_test(save_path=None, filename="current_image.jpg"):
    """æ‹ç…§å‡½æ•°
    Args:
        save_path: ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä¿å­˜åˆ°å½“å‰ç›®å½•
        filename: æ–‡ä»¶åï¼Œé»˜è®¤ä¸ºcurrent_image.jpg
    """
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    current_file = os.path.abspath(__file__)
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file)))
    
    # å¯¼å…¥ç›¸æœºç®¡ç†å™¨å¹¶ç›´æ¥è°ƒç”¨
    try:
        import sys
        sys.path.insert(0, project_root)
        from core.camera.camera_manager import CameraManager
        
        camera = CameraManager()
        result = camera.take_photo(filename=filename, save_path=save_path)
        
        if result:
            print(f"æ‹ç…§å®Œæˆï¼Œç…§ç‰‡ä¿å­˜è‡³: {result}")
            return result
        else:
            print("æ‹ç…§å¤±è´¥")
            return None
            
    except Exception as e:
        print(f"æ‹ç…§è¿‡ç¨‹å‡ºé”™: {e}")
        return None

def encode_image(image_path):
    """ç¼–ç å›¾ç‰‡æˆbase64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8") 
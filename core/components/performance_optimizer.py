"""
å²è±å§†æ¼‚æµæ€§èƒ½ä¼˜åŒ–å·¥å…·

è¯¥æ¨¡å—æä¾›ç»Ÿä¸€çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼š
- APIè°ƒç”¨ç¼“å­˜å’Œå»é‡
- æ™ºèƒ½é‡è¯•æœºåˆ¶
- èµ„æºç®¡ç†
- é”™è¯¯æ¢å¤
"""

import time
import hashlib
import pickle
import os
from typing import Dict, Any, Optional, Callable, Tuple
from functools import wraps

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨ï¼Œæä¾›ç¼“å­˜ã€é‡è¯•ã€å»é‡ç­‰åŠŸèƒ½"""
    
    def __init__(self, cache_dir: str = None, enable_cache: bool = True):
        self.enable_cache = enable_cache
        self.cache_dir = cache_dir or os.path.join(os.getcwd(), '.derive_cache')
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.api_call_times = {}  # APIè°ƒç”¨æ—¶é—´è®°å½•
        self.failure_counts = {}  # å¤±è´¥è®¡æ•°å™¨
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        if self.enable_cache and not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
    
    def cache_key(self, func_name: str, *args, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # å°†å‚æ•°åºåˆ—åŒ–å¹¶ç”Ÿæˆå“ˆå¸Œ
        cache_data = {
            'func': func_name,
            'args': args,
            'kwargs': kwargs
        }
        cache_str = pickle.dumps(cache_data, protocol=pickle.HIGHEST_PROTOCOL)
        return hashlib.md5(cache_str).hexdigest()
    
    def get_cache(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        if not self.enable_cache:
            return None
        
        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if key in self.memory_cache:
            return self.memory_cache[key]
        
        # æ£€æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = os.path.join(self.cache_dir, f"{key}.cache")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    data = pickle.load(f)
                    # åŒæ—¶å­˜å…¥å†…å­˜ç¼“å­˜
                    self.memory_cache[key] = data
                    return data
            except Exception:
                # ç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ é™¤å®ƒ
                os.remove(cache_file)
        
        return None
    
    def set_cache(self, key: str, value: Any) -> None:
        """è®¾ç½®ç¼“å­˜"""
        if not self.enable_cache:
            return
        
        # å­˜å…¥å†…å­˜ç¼“å­˜
        self.memory_cache[key] = value
        
        # å­˜å…¥ç£ç›˜ç¼“å­˜
        cache_file = os.path.join(self.cache_dir, f"{key}.cache")
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(value, f, protocol=pickle.HIGHEST_PROTOCOL)
        except Exception:
            # ç¼“å­˜å†™å…¥å¤±è´¥ï¼Œå¿½ç•¥
            pass
    
    def is_api_rate_limited(self, api_name: str, min_interval: float = 1.0) -> bool:
        """æ£€æŸ¥APIæ˜¯å¦è¢«é¢‘ç‡é™åˆ¶"""
        current_time = time.time()
        last_call_time = self.api_call_times.get(api_name, 0)
        
        if current_time - last_call_time < min_interval:
            return True
        
        return False
    
    def record_api_call(self, api_name: str) -> None:
        """è®°å½•APIè°ƒç”¨æ—¶é—´"""
        self.api_call_times[api_name] = time.time()
    
    def get_failure_count(self, operation: str) -> int:
        """è·å–æ“ä½œå¤±è´¥æ¬¡æ•°"""
        return self.failure_counts.get(operation, 0)
    
    def record_failure(self, operation: str) -> None:
        """è®°å½•æ“ä½œå¤±è´¥"""
        self.failure_counts[operation] = self.failure_counts.get(operation, 0) + 1
    
    def reset_failure_count(self, operation: str) -> None:
        """é‡ç½®æ“ä½œå¤±è´¥è®¡æ•°"""
        self.failure_counts[operation] = 0
    
    def smart_retry(self, 
                   func: Callable, 
                   max_retries: int = 3, 
                   base_delay: float = 1.0,
                   exponential_backoff: bool = True,
                   retry_on_exceptions: Tuple = (Exception,),
                   operation_name: str = None) -> Any:
        """æ™ºèƒ½é‡è¯•æœºåˆ¶
        
        Args:
            func: è¦æ‰§è¡Œçš„å‡½æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´
            exponential_backoff: æ˜¯å¦ä½¿ç”¨æŒ‡æ•°é€€é¿
            retry_on_exceptions: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹
            operation_name: æ“ä½œåç§°ï¼Œç”¨äºå¤±è´¥ç»Ÿè®¡
        """
        operation = operation_name or func.__name__
        
        for attempt in range(max_retries + 1):
            try:
                result = func()
                # æˆåŠŸåˆ™é‡ç½®å¤±è´¥è®¡æ•°
                self.reset_failure_count(operation)
                return result
                
            except retry_on_exceptions as e:
                self.record_failure(operation)
                
                if attempt == max_retries:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    print(f"âŒ {operation} é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥: {str(e)}")
                    raise
                
                # è®¡ç®—å»¶è¿Ÿæ—¶é—´
                if exponential_backoff:
                    delay = base_delay * (2 ** attempt)
                else:
                    delay = base_delay
                
                print(f"âš ï¸  {operation} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {str(e)}")
                print(f"ğŸ”„ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                
                time.sleep(delay)
    
    def clear_cache(self, pattern: str = None) -> None:
        """æ¸…ç†ç¼“å­˜"""
        # æ¸…ç†å†…å­˜ç¼“å­˜
        if pattern:
            keys_to_remove = [k for k in self.memory_cache.keys() if pattern in k]
            for key in keys_to_remove:
                del self.memory_cache[key]
        else:
            self.memory_cache.clear()
        
        # æ¸…ç†ç£ç›˜ç¼“å­˜
        if os.path.exists(self.cache_dir):
            for filename in os.listdir(self.cache_dir):
                if filename.endswith('.cache'):
                    if not pattern or pattern in filename:
                        try:
                            os.remove(os.path.join(self.cache_dir, filename))
                        except Exception:
                            pass

def cached_api_call(optimizer: PerformanceOptimizer, 
                   api_name: str, 
                   cache_duration: int = 300,  # 5åˆ†é’Ÿç¼“å­˜
                   rate_limit: float = 1.0):
    """APIè°ƒç”¨ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = optimizer.cache_key(api_name, *args, **kwargs)
            
            # æ£€æŸ¥ç¼“å­˜
            cached_result = optimizer.get_cache(cache_key)
            if cached_result is not None:
                print(f"ğŸ¯ ä½¿ç”¨ç¼“å­˜ç»“æœ: {api_name}")
                return cached_result
            
            # æ£€æŸ¥é¢‘ç‡é™åˆ¶
            if optimizer.is_api_rate_limited(api_name, rate_limit):
                wait_time = rate_limit - (time.time() - optimizer.api_call_times.get(api_name, 0))
                print(f"â³ APIé¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
                time.sleep(wait_time)
            
            # æ‰§è¡ŒAPIè°ƒç”¨
            def api_call():
                optimizer.record_api_call(api_name)
                return func(*args, **kwargs)
            
            # ä½¿ç”¨æ™ºèƒ½é‡è¯•
            result = optimizer.smart_retry(
                api_call,
                max_retries=3,
                operation_name=f"api_{api_name}"
            )
            
            # ç¼“å­˜ç»“æœ
            optimizer.set_cache(cache_key, result)
            
            return result
        
        return wrapper
    return decorator

class ResourceManager:
    """èµ„æºç®¡ç†å™¨ï¼Œç¡®ä¿èµ„æºçš„æ­£ç¡®åˆ†é…å’Œé‡Šæ”¾"""
    
    def __init__(self):
        self.active_resources = {}  # æ´»è·ƒèµ„æº
        self.resource_locks = {}    # èµ„æºé”
    
    def acquire_resource(self, resource_name: str, resource_obj: Any) -> None:
        """è·å–èµ„æº"""
        if resource_name in self.active_resources:
            print(f"âš ï¸  èµ„æº {resource_name} å·²å­˜åœ¨ï¼Œå°†è¢«æ›¿æ¢")
            self.release_resource(resource_name)
        
        self.active_resources[resource_name] = resource_obj
        print(f"ğŸ“Œ è·å–èµ„æº: {resource_name}")
    
    def release_resource(self, resource_name: str) -> None:
        """é‡Šæ”¾èµ„æº"""
        if resource_name in self.active_resources:
            resource = self.active_resources[resource_name]
            
            # å°è¯•è°ƒç”¨èµ„æºçš„æ¸…ç†æ–¹æ³•
            cleanup_methods = ['cleanup', 'close', 'dispose', 'clear']
            for method_name in cleanup_methods:
                if hasattr(resource, method_name):
                    try:
                        getattr(resource, method_name)()
                        print(f"ğŸ§¹ é‡Šæ”¾èµ„æº: {resource_name} (è°ƒç”¨ {method_name})")
                        break
                    except Exception as e:
                        print(f"âš ï¸  é‡Šæ”¾èµ„æº {resource_name} æ—¶å‡ºé”™: {e}")
            
            del self.active_resources[resource_name]
    
    def release_all(self) -> None:
        """é‡Šæ”¾æ‰€æœ‰èµ„æº"""
        for resource_name in list(self.active_resources.keys()):
            self.release_resource(resource_name)
    
    def get_resource_status(self) -> Dict[str, str]:
        """è·å–èµ„æºçŠ¶æ€"""
        status = {}
        for name, resource in self.active_resources.items():
            status[name] = f"{type(resource).__name__} - {id(resource)}"
        return status

# å…¨å±€æ€§èƒ½ä¼˜åŒ–å™¨å®ä¾‹
global_optimizer = PerformanceOptimizer()
global_resource_manager = ResourceManager() 
from typing import Optional
import os

from ..abstract_state import AbstractState
from ..derive_states import DeriveState
from ..derive_utils import DeriveChatUtils, encode_image

class ProcessPhotoVoiceState(AbstractState):
    """å¤„ç†æ‹ç…§+è¯­éŸ³æ•°æ®çŠ¶æ€"""
    
    def __init__(self):
        super().__init__(DeriveState.PROCESS_PHOTO_VOICE)
    
    def execute(self, context) -> None:
        """æ‰§è¡Œæ‹ç…§+è¯­éŸ³æ•°æ®å¤„ç†é€»è¾‘"""
        context.logger.log_step("å¤„ç†æ‹ç…§+è¯­éŸ³", "å¼€å§‹å¤„ç†æ‹ç…§æ—¶çš„è¯­éŸ³å’Œç…§ç‰‡æ•°æ®")
        
        try:
            # è·å–æ‹ç…§è¯­éŸ³å’Œç…§ç‰‡æ•°æ®
            photo_voice_text = context.get_data('photo_voice_text')
            photo_path = context.get_data('timestamped_image')
            
            if not photo_voice_text:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°æ‹ç…§æ—¶çš„è¯­éŸ³æ–‡æœ¬")
            
            context.logger.log_step("æ•°æ®è·å–", f"æ‹ç…§è¯­éŸ³æ–‡æœ¬: {photo_voice_text[:50]}...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç…§ç‰‡ï¼ˆå¦‚æœæ‹ç…§å¤±è´¥å¯èƒ½æ²¡æœ‰ï¼‰
            if photo_path and not context.get_data('photo_failed'):
                # æœ‰ç…§ç‰‡ï¼Œè¿›è¡Œç…§ç‰‡+è¯­éŸ³ç»„åˆåˆ†æ
                self._analyze_photo_with_voice(context, photo_path, photo_voice_text)
            else:
                # ä»…åˆ†æè¯­éŸ³æ–‡æœ¬
                self._analyze_voice_only(context, photo_voice_text)
            
            context.logger.log_step("å¤„ç†æ‹ç…§+è¯­éŸ³", "æ‹ç…§+è¯­éŸ³æ•°æ®å¤„ç†å®Œæˆ")
            
        except Exception as e:
            context.logger.log_step("é”™è¯¯", f"å¤„ç†æ‹ç…§+è¯­éŸ³æ•°æ®å¤±è´¥: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä½¿ç”¨é»˜è®¤å¤„ç†
            self._use_fallback_analysis(context)
    
    def _analyze_photo_with_voice(self, context, photo_path: str, voice_text: str):
        """åˆ†æç…§ç‰‡+è¯­éŸ³ç»„åˆæ•°æ®"""
        context.oled_display.show_text_oled("æ­£åœ¨åˆ†æ\nç…§ç‰‡å’Œè¯­éŸ³...")
        
        try:
            # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            context.logger.log_step("ğŸ” è°ƒè¯•ä¿¡æ¯", f"å¼€å§‹åˆ†æç…§ç‰‡+è¯­éŸ³")
            context.logger.log_step("ğŸ“ ç…§ç‰‡è·¯å¾„", f"åŸå§‹è·¯å¾„: {photo_path}")
            context.logger.log_step("ğŸ—£ï¸ è¯­éŸ³æ–‡æœ¬", f"æ–‡æœ¬é•¿åº¦: {len(voice_text)}, å†…å®¹: {voice_text[:100]}...")
            
            # æ£€æŸ¥ç…§ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(photo_path):
                raise FileNotFoundError(f"ç…§ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {photo_path}")
            
            # è·å–ç»å¯¹è·¯å¾„
            abs_photo_path = os.path.abspath(photo_path)
            context.logger.log_step("ğŸ“ ç»å¯¹è·¯å¾„", f"ç»å¯¹è·¯å¾„: {abs_photo_path}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(photo_path)
            context.logger.log_step("ğŸ“ æ–‡ä»¶å¤§å°", f"æ–‡ä»¶å¤§å°: {file_size} bytes")
            
            if file_size == 0:
                raise ValueError("ç…§ç‰‡æ–‡ä»¶ä¸ºç©º")
            
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶
            try:
                from PIL import Image
                with Image.open(photo_path) as img:
                    img_format = img.format
                    img_mode = img.mode  
                    img_size = img.size
                    context.logger.log_step("ğŸ–¼ï¸ å›¾ç‰‡ä¿¡æ¯", f"æ ¼å¼: {img_format}, æ¨¡å¼: {img_mode}, å°ºå¯¸: {img_size}")
            except Exception as e:
                context.logger.log_step("âŒ å›¾ç‰‡éªŒè¯å¤±è´¥", f"ä¸æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶: {str(e)}")
                raise ValueError(f"æ— æ•ˆçš„å›¾ç‰‡æ–‡ä»¶: {str(e)}")
            
            # ç¼–ç ç…§ç‰‡ä¸ºbase64
            context.logger.log_step("ğŸ”„ å¼€å§‹ç¼–ç ", "å¼€å§‹Base64ç¼–ç ...")
            base64_image = encode_image(photo_path)
            base64_length = len(base64_image)
            context.logger.log_step("âœ… ç¼–ç å®Œæˆ", f"Base64é•¿åº¦: {base64_length} å­—ç¬¦")
            context.logger.log_step("ğŸ”¤ Base64é¢„è§ˆ", f"å‰100å­—ç¬¦: {base64_image[:100]}")
            
            # éªŒè¯base64ç¼–ç æ˜¯å¦æœ‰æ•ˆ
            if base64_length < 100:
                raise ValueError(f"Base64ç¼–ç å¼‚å¸¸çŸ­: {base64_length} å­—ç¬¦")
            
            # æ„å»ºdata URL
            data_url = f"data:image/jpeg;base64,{base64_image}"
            data_url_length = len(data_url)
            context.logger.log_step("ğŸ”— Data URL", f"Data URLæ€»é•¿åº¦: {data_url_length} å­—ç¬¦")
            context.logger.log_step("ğŸ”— Data URLå¤´éƒ¨", f"å¤´éƒ¨: {data_url[:50]}...")
            
            # ä½¿ç”¨èŠå¤©å·¥å…·è¿›è¡Œç»„åˆåˆ†æ
            chat_utils = DeriveChatUtils(context.response_id)
            
            # æ„å»ºç…§ç‰‡+è¯­éŸ³åˆ†ææç¤º
            analysis_prompt = f"""
            è¯·ç»“åˆè¿™å¼ ç…§ç‰‡å’Œç”¨æˆ·åœ¨æ‹ç…§æ—¶è¯´çš„è¯æ¥è¿›è¡Œç»¼åˆåˆ†æã€‚
            
            ç”¨æˆ·æ‹ç…§æ—¶çš„è¯­éŸ³æè¿°: "{voice_text}"
            
            è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æ:
            1. ç…§ç‰‡ä¸­å±•ç°çš„è§†è§‰å†…å®¹
            2. ç”¨æˆ·è¯­éŸ³ä¸­è¡¨è¾¾çš„ä¸»è§‚æ„Ÿå—
            3. è§†è§‰ä¸æ„Ÿå—çš„ç»“åˆç‚¹
            4. è¿™ä¸ªåœºæ™¯ç»™äººçš„æ•´ä½“å°è±¡
            5. é€‚åˆä»€ä¹ˆæ ·çš„å²è±å§†è§’è‰²
            
            è¯·ç”¨ä¸°å¯Œçš„æè¿°æ€§è¯­è¨€å›ç­”ï¼Œæ§åˆ¶åœ¨200å­—ä»¥å†…ã€‚
            """
            
            # æ„å»ºè¾“å…¥å†…å®¹
            input_content = [
                {"type": "input_text", "text": analysis_prompt},
                {"type": "input_image", "image_url": data_url}
            ]
            
            context.logger.log_step("ğŸ“ æç¤ºè¯", f"æç¤ºè¯é•¿åº¦: {len(analysis_prompt)}")
            context.logger.log_step("ğŸ“‹ è¾“å…¥æ ¼å¼", f"è¾“å…¥åŒ…å« {len(input_content)} ä¸ªå…ƒç´ ")
            context.logger.log_step("ğŸ“‹ è¾“å…¥ç»“æ„", f"å…ƒç´ 1ç±»å‹: {input_content[0]['type']}, å…ƒç´ 2ç±»å‹: {input_content[1]['type']}")
            
            context.logger.log_step("ğŸ¤– å‘é€è¯·æ±‚", "å‘é€ç…§ç‰‡+è¯­éŸ³åˆ°AI...")
            
            # è°ƒç”¨åˆ†æ
            combined_analysis = chat_utils.chat_with_continuity(input_content)
            
            context.logger.log_step("ğŸ“¨ AIå›å¤", f"å›å¤é•¿åº¦: {len(combined_analysis)}")
            context.logger.log_step("ğŸ“¨ AIå›å¤å†…å®¹", f"å®Œæ•´å›å¤: {combined_analysis}")
            
            # æ£€æŸ¥AIæ˜¯å¦çœŸçš„çœ‹åˆ°äº†ç…§ç‰‡
            failure_keywords = ["æŠ±æ­‰", "æ— æ³•", "ä¸èƒ½", "çœ‹ä¸åˆ°", "æ— æ³•æŸ¥çœ‹", "cannot", "can't", "sorry", "unable"]
            success_keywords = ["çœ‹åˆ°", "å›¾ç‰‡", "ç…§ç‰‡", "ç”»é¢", "ç”»ä¸­", "see", "image", "photo"]
            
            has_failure_keywords = any(keyword in combined_analysis.lower() for keyword in failure_keywords)
            has_success_keywords = any(keyword in combined_analysis.lower() for keyword in success_keywords)
            
            context.logger.log_step("ğŸ” å…³é”®è¯åˆ†æ", f"å¤±è´¥å…³é”®è¯: {has_failure_keywords}, æˆåŠŸå…³é”®è¯: {has_success_keywords}")
            
            if has_failure_keywords and not has_success_keywords:
                context.logger.log_step("âš ï¸ AIåˆ†æè­¦å‘Š", "AIå¯èƒ½æ— æ³•è¯†åˆ«ç…§ç‰‡å†…å®¹")
                context.logger.log_step("âš ï¸ å¤±è´¥åŸå› ", "æ£€æµ‹åˆ°æ‹’ç»æ€§å…³é”®è¯ï¼Œä¸”æ²¡æœ‰æˆåŠŸå…³é”®è¯")
                
                # å›é€€åˆ°ä»…è¯­éŸ³åˆ†æï¼Œä½†è®°å½•ç…§ç‰‡é—®é¢˜
                context.logger.log_step("ğŸ”„ å¤„ç†ç­–ç•¥", "AIæ— æ³•è¯†åˆ«ç…§ç‰‡ï¼Œå›é€€åˆ°è¯­éŸ³åˆ†æ")
                self._analyze_voice_only(context, voice_text)
                return
            
            # ä¿å­˜åˆ†æç»“æœ
            context.set_data('photo_description', combined_analysis)
            context.set_data('voice_enhanced_analysis', True)  # æ ‡è®°ä¸ºè¯­éŸ³å¢å¼ºåˆ†æ
            context.response_id = chat_utils.response_id
            
            context.logger.log_step("âœ… ç…§ç‰‡+è¯­éŸ³åˆ†ææˆåŠŸ", combined_analysis)
            
        except Exception as e:
            context.logger.log_step("âŒ ç…§ç‰‡+è¯­éŸ³åˆ†æé”™è¯¯", f"åˆ†æå¤±è´¥: {str(e)}")
            context.logger.log_step("âŒ é”™è¯¯è¯¦æƒ…", f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            # å›é€€åˆ°ä»…è¯­éŸ³åˆ†æ
            self._analyze_voice_only(context, voice_text)
    
    def _analyze_voice_only(self, context, voice_text: str):
        """ä»…åˆ†æè¯­éŸ³æ–‡æœ¬ï¼ˆå½“æ²¡æœ‰ç…§ç‰‡æ—¶ï¼‰"""
        context.oled_display.show_text_oled("æ­£åœ¨åˆ†æ\nè¯­éŸ³æè¿°...")
        
        try:
            # ä½¿ç”¨èŠå¤©å·¥å…·åˆ†æè¯­éŸ³å†…å®¹
            chat_utils = DeriveChatUtils(context.response_id)
            
            # æ„å»ºè¯­éŸ³åˆ†ææç¤º
            voice_analysis_prompt = f"""
            ç”¨æˆ·åœ¨æŸä¸ªåœºæ™¯ä¸­è¡¨è¾¾äº†è¿™æ ·çš„æ„Ÿå—å’Œæè¿°: "{voice_text}"
            
            è¯·åŸºäºè¿™æ®µè¯åˆ†æ:
            1. ç”¨æˆ·å½“æ—¶æ‰€å¤„çš„ç¯å¢ƒå¯èƒ½æ˜¯ä»€ä¹ˆæ ·çš„
            2. ç”¨æˆ·çš„å¿ƒç†çŠ¶æ€å’Œæƒ…æ„Ÿå€¾å‘
            3. è¿™ä¸ªåœºæ™¯çš„æ°›å›´å’Œç‰¹ç‚¹
            4. é€‚åˆç”Ÿæˆä»€ä¹ˆæ ·çš„å²è±å§†è§’è‰²æ¥åŒ¹é…è¿™ç§æ„Ÿå—
            
            è¯·ç”¨ç”ŸåŠ¨çš„æè¿°å›ç­”ï¼Œæ§åˆ¶åœ¨150å­—ä»¥å†…ã€‚
            """
            
            # è°ƒç”¨åˆ†æ
            voice_analysis = chat_utils.chat_with_continuity(voice_analysis_prompt)
            
            # ä¿å­˜åˆ†æç»“æœ
            context.set_data('photo_description', voice_analysis)
            context.set_data('voice_only_analysis', True)  # æ ‡è®°ä¸ºä»…è¯­éŸ³åˆ†æ
            context.response_id = chat_utils.response_id
            
            context.logger.log_step("è¯­éŸ³åˆ†æ", voice_analysis)
            
        except Exception as e:
            context.logger.log_step("é”™è¯¯", f"è¯­éŸ³åˆ†æå¤±è´¥: {str(e)}")
            self._use_fallback_analysis(context)
    
    def _use_fallback_analysis(self, context):
        """ä½¿ç”¨å¤‡ç”¨åˆ†æï¼ˆå½“æ‰€æœ‰åˆ†æéƒ½å¤±è´¥æ—¶ï¼‰"""
        fallback_description = "è¿™æ˜¯ä¸€ä¸ªå……æ»¡å¯èƒ½æ€§çš„åœ°æ–¹ï¼Œåœ¨è¿™é‡Œå¯ä»¥æ„Ÿå—åˆ°ç‹¬ç‰¹çš„æ°›å›´å’Œç¾å¥½çš„ä½“éªŒã€‚"
        context.set_data('photo_description', fallback_description)
        context.set_data('fallback_analysis', True)
        
        context.logger.log_step("å¤‡ç”¨åˆ†æ", "ä½¿ç”¨é»˜è®¤åœºæ™¯æè¿°")
        
        context.oled_display.show_text_oled(
            "åˆ†æå®Œæˆ\nä½¿ç”¨é»˜è®¤æè¿°\n\næŒ‰BT1ç»§ç»­"
        )
        
        context.oled_display.wait_for_button_with_text(
            context.controller,
            "å‡†å¤‡ç»§ç»­æµç¨‹...",
            context=context
        )
    
    def get_next_state(self, context) -> Optional[DeriveState]:
        """è¿”å›ä¸‹ä¸€ä¸ªçŠ¶æ€"""
        if context.should_return_to_menu():
            return DeriveState.EXIT
        
        # æ­£å¸¸æƒ…å†µä¸‹è¿›å…¥å»ºè®®ç›®çš„åœ°çŠ¶æ€
        return DeriveState.SUGGEST_DESTINATION 
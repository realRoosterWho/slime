import subprocess
import os
import sys
import base64
import replicate
import requests
import time
import json
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from display_utils import DisplayManager
import signal
import shutil
from button_utils import InputController
from enum import Enum, auto
import RPi.GPIO as GPIO  # æ·»åŠ è¿™ä¸ªå¯¼å…¥
from PIL import Image
from io import BytesIO

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
replicate_api_key = os.getenv("REPLICATE_API_KEY")

if not replicate_api_key:
    raise Exception("æ²¡æœ‰æ‰¾åˆ°REPLICATE_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶è®¾ç½®ï¼")

replicate_client = replicate.Client(api_token=replicate_api_key)

class DeriveLogger:
    def __init__(self):
        self.current_dir = os.path.dirname(os.path.abspath(__file__))
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_dir = os.path.join(self.current_dir, "derives", self.timestamp)
        os.makedirs(self.log_dir, exist_ok=True)
        
        self.log_data = {
            "timestamp": self.timestamp,
            "steps": [],
            "images": {},
            "prompts": {},
            "responses": {}
        }
    
    def log_step(self, step_name, message):
        """è®°å½•æ­¥éª¤ä¿¡æ¯"""
        print(f"\nğŸ“ {message}")
        self.log_data["steps"].append({
            "time": datetime.now().strftime("%H:%M:%S"),
            "step": step_name,
            "message": message
        })
        
    def save_image(self, image_path, image_type):
        """ä¿å­˜å›¾ç‰‡åˆ°æ—¥å¿—ç›®å½•"""
        if os.path.exists(image_path):
            filename = os.path.basename(image_path)
            new_path = os.path.join(self.log_dir, filename)
            shutil.copy2(image_path, new_path)
            self.log_data["images"][image_type] = filename
            return new_path
        return None
    
    def log_prompt(self, prompt_type, prompt):
        """è®°å½•æç¤ºè¯"""
        self.log_data["prompts"][prompt_type] = prompt
    
    def log_response(self, response_type, response):
        """è®°å½•å“åº”"""
        self.log_data["responses"][response_type] = response
    
    def save_log(self):
        """ä¿å­˜æ—¥å¿—æ–‡ä»¶"""
        log_path = os.path.join(self.log_dir, "derive_log.json")
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(self.log_data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")

    def get_timestamped_filename(self, original_name, ext):
        """ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å"""
        base_name = os.path.splitext(original_name)[0]
        return f"{base_name}_{self.timestamp}{ext}"

def chat_with_gpt(input_content, system_content=None, previous_response_id=None):
    """ä¸GPTè¿›è¡Œå¯¹è¯"""
    # å¦‚æœè¾“å…¥æ˜¯åˆ—è¡¨ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
    if isinstance(input_content, list):
        messages = input_content
    else:
        # å¦åˆ™æ„å»ºæ™®é€šæ–‡æœ¬æ¶ˆæ¯
        messages = [{"type": "input_text", "text": input_content}]
        
    if system_content:
        messages.insert(0, {"type": "input_text", "text": system_content})
        
    response = client.responses.create(
        model="gpt-4o-mini",
        input=messages,
        previous_response_id=previous_response_id
    )
    return response

def run_camera_test():
    """æ‹ç…§å‡½æ•°"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    camera_script = os.path.join(current_dir, "camera_test.py")

    try:
        print("å¯åŠ¨æ‹ç…§è„šæœ¬...")
        subprocess.run(["/usr/bin/python3", camera_script], check=True)
        print("æ‹ç…§å®Œæˆã€‚")
    except subprocess.CalledProcessError as e:
        print(f"æ‹ç…§è„šæœ¬è¿è¡Œå‡ºé”™: {e}")

def encode_image(image_path):
    """ç¼–ç å›¾ç‰‡æˆbase64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def cleanup_handler(signum, frame):
    """æ¸…ç†èµ„æºå¹¶ä¼˜é›…é€€å‡º"""
    print("\nğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")
    try:
        if 'lcd_display' in globals():
            lcd_display.clear()
        if 'oled_display' in globals():
            oled_display.clear()
        print("âœ… å·²æ¸…ç†æ˜¾ç¤ºèµ„æº")
    except:
        pass
    sys.exit(0)

def download_with_retry(url, max_retries=3, delay=1):
    """å¸¦é‡è¯•æœºåˆ¶çš„ä¸‹è½½å‡½æ•°"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return response
            print(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå°è¯•é‡è¯•...")
        except requests.exceptions.RequestException as e:
            print(f"ä¸‹è½½å‡ºé”™ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(delay)
                continue
            raise
    return None

class DeriveState(Enum):
    """æ¼‚æµçŠ¶æ€æšä¸¾"""
    INIT = auto()                  # åˆå§‹åŒ–
    GEN_SLIME_IMAGE = auto()       # ç”Ÿæˆå²è±å§†å›¾ç‰‡
    SHOW_SLIME_IMAGE = auto()      # æ˜¾ç¤ºå²è±å§†å›¾ç‰‡
    SHOW_GREETING = auto()         # æ˜¾ç¤ºæ‰“æ‹›å‘¼
    ASK_PHOTO = auto()            # è¯¢é—®æ‹ç…§
    TAKE_PHOTO = auto()           # æ‹ç…§
    ANALYZE_PHOTO = auto()        # åˆ†æç…§ç‰‡
    SUGGEST_DESTINATION = auto()   # å»ºè®®ç›®çš„åœ°
    CLEANUP = auto()              # æ¸…ç†
    EXIT = auto()                 # é€€å‡º

class DeriveStateMachine:
    def __init__(self, initial_text):
        # åœ¨ç±»åˆå§‹åŒ–æ—¶è®¾ç½® GPIO æ¨¡å¼
        GPIO.setmode(GPIO.BCM)
        GPIO.setwarnings(False)
        
        self.logger = DeriveLogger()
        self.oled_display = DisplayManager("OLED")
        self.lcd_display = DisplayManager("LCD")
        self.controller = InputController()
        self.state = DeriveState.INIT
        self.initial_text = initial_text
        self.response_id = None
        self.data = {
            'personality': None,
            'greeting': None,
            'photo_description': None,
            'destination_suggestion': None,
            'image_path': None,
            'timestamped_image': None,
            'slime_image': None,
            'slime_description': None
        }
        
        # è®¾ç½® Replicate API token
        replicate_api_key = os.getenv("REPLICATE_API_KEY")
        if not replicate_api_key:
            raise Exception("æ²¡æœ‰æ‰¾åˆ°REPLICATE_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶è®¾ç½®ï¼")
        os.environ["REPLICATE_API_TOKEN"] = replicate_api_key

    def chat_with_continuity(self, prompt, system_content=None):
        """å¸¦è¿ç»­æ€§çš„å¯¹è¯å‡½æ•°"""
        response = chat_with_gpt(
            input_content=prompt,  # prompt å¯ä»¥æ˜¯æ–‡æœ¬æˆ–åŒ…å«å›¾ç‰‡çš„åˆ—è¡¨
            system_content=system_content,
            previous_response_id=self.response_id
        )
        self.response_id = response.id  # ä¿å­˜å“åº”IDä»¥ç»´æŒå¯¹è¯è¿ç»­æ€§
        if hasattr(response.output[0].content[0], 'text'):
            return response.output[0].content[0].text.strip()
        return response.output[0].content[0]

    def wait_for_button(self, display_text):
        """ç­‰å¾…æŒ‰é’®ç‚¹å‡»çš„é€šç”¨å‡½æ•°"""
        self.oled_display.wait_for_button_with_text(
            self.controller,
            display_text
        )

    def generate_text_prompt(self, prompt_type):
        """ç”Ÿæˆä¸åŒç±»å‹æ–‡æœ¬çš„æç¤ºè¯æ¨¡æ¿"""
        prompts = {
            'personality': (
                """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§’è‰²è®¾å®šå¸ˆã€‚æ ¹æ®ç¯å¢ƒæˆ–ç‰©ä½“çš„æè¿°ï¼Œå¸®æˆ‘è®¾å®šä¸€åªå²è±å§†çš„æ€§æ ¼ç‰¹ç‚¹ï¼Œç”¨ä¸­æ–‡ç®€æ´æè¿°ï¼Œä¸è¦å¤ªé•¿ï¼Œæƒ…æ„Ÿè¦ç»†è…»ã€‚ä»¥ä¸‹æ˜¯ä½ è®¾è®¡è§’è‰²çš„ä¸€èˆ¬è¦æ±‚ï¼š

                - ã€æè¿°ï¼ˆDescriptionï¼‰ã€‘ï¼š"å²è±å§†"çš„"æƒ…ç»ªä¸»é¢˜"ã€‚æ¯ä¸€ä¸ªå²è±å§†éƒ½æ˜¯ç”±å…ˆå‰ç©å®¶çš„"æ¼‚æµ"ç»éªŒä¸­æ”¶è·çš„"å²è±å§†è›‹"ç”Ÿæˆçš„ï¼Œç©å®¶åœ¨æ¯æ¬¡æ¼‚æµå‰å†³å®šäº†é€‰æ‹©å¸¦å“ªä¸€ä¸ª"å²è±å§†"è¿›è¡Œæ¼‚æµï¼Œè¿™ä¹Ÿå†³å®šäº†æœ¬æ¬¡æ¼‚æµçš„"ä¸»é¢˜"ã€‚è¿™ä¸ªå±æ€§æ˜¯å†³å®šæ€§çš„ï¼Œæ¥ä¸‹æ¥çš„å±æ€§ä¹Ÿæ˜¯ç”±"æè¿°"è¿™ä¸ªå±æ€§ç”Ÿæˆçš„ã€‚
                - ã€æ‰§å¿µï¼ˆObsessionï¼‰ã€‘ï¼š"å²è±å§†"æ¼‚æµä¸­çš„å…·è±¡ç›®æ ‡ã€‚æ ¹æ®"å²è±å§†"çš„æ€§æ ¼ï¼Œåœ¨æ¼‚æµä¸­"å²è±å§†"ä¼šå¼•å¯¼ç©å®¶å¯»æ‰¾ä¸åŒçš„é£æ™¯ï¼Œä¹Ÿæ˜¯æç¤ºè¯çš„åŸºç¡€è®¾å®šã€‚
                - ã€å¹»æƒ³ç™–å¥½ï¼ˆQuirkï¼‰ã€‘ï¼šç›®æ ‡è¾¾æˆçš„æ­£å‘åé¦ˆã€‚å¦‚æœæ‰¾åˆ°äº†"åˆé€‚"çš„é£æ™¯ï¼Œ"å²è±å§†"å°†ä¼šå…·æœ‰çš„ååº”ã€‚è¿™äº›å¥–åŠ±ä¸"å²è±å§†"çš„"æ‰§å¿µ"ç›¸å…³ï¼Œæœ€åä¼šç”Ÿæˆ"è£…æ‰®å¥–åŠ±"ã€‚
                - ã€åæ‰§ååº”ï¼ˆReflexï¼‰ã€‘ï¼šç›®æ ‡æœªè¾¾æˆçš„æ„å¤–åé¦ˆã€‚å¦‚æœæ‰¾åˆ°äº†"ä¸åˆé€‚"çš„é£æ™¯ï¼Œ"å²è±å§†"ä¼šæœ‰çš„ååº”ã€‚è¿™äº›å¥–åŠ±è™½ç„¶æ²¡åŠæ³•è¾¾æˆ"å²è±å§†"çš„æ‰§å¿µï¼Œä½†æ˜¯å®ƒä»ç„¶ä¼šæœ‰ç¬¦åˆæ€§æ ¼çš„åé¦ˆï¼Œå¹¶ä¸”è¿˜ä¼šç”Ÿæˆæ„å¤–çš„"å²è±å§†è›‹"å¥–åŠ±ã€‚
                - ã€äº’åŠ¨è¯­æ°”ï¼ˆInteraction Toneï¼‰ã€‘ï¼šæ ¹æ®ä»¥ä¸Šå±æ€§ç”Ÿæˆçš„äº’åŠ¨é¢„æœŸã€‚æ¯æ¬¡äº’åŠ¨ä¸ä»…æœ‰å¥–åŠ±çš„åé¦ˆï¼Œè¿˜éœ€è¦æœ‰å³æ—¶çš„äº’åŠ¨åé¦ˆã€‚

                ä»¥ä¸‹æ˜¯å…·ä½“çš„ä¾‹å­ï¼š

                > ã€ç»ç’ƒé’æŸ çš„å²è±å§†ã€‘ï¼š"ä»–è¿·æ‹æ‰€æœ‰åŠé€æ˜ã€é€äº®çš„ä¸œè¥¿ï¼Œå¸¸å¸¸ç›¯ç€å®ƒä»¬å‡ºç¥ï¼Œå¹»æƒ³ç€'å¦‚æœæŠŠå®ƒä»¬æ‰“ç¢ï¼Œä¼šä¸ä¼šå†’å‡ºæŸ æª¬å‘³çš„é¦™æ°”ï¼Ÿ'ç„¶åè®°ä¸‹æ¥ï¼Œå‡†å¤‡åšæˆä¸€æ¯ç‹¬ä¸€æ— äºŒçš„æœæ±ã€‚"
                > 
                > - **æ‰§å¿µ**ï¼šé€æ˜çš„ä¸œè¥¿é‡Œé¢ä¸€å®šè—ç€ç‹¬ç‰¹çš„é¦™æ°”ï¼Œéœ€è¦å¯»æ‰¾é€æ˜çš„ä¸œè¥¿
                > - å¹»æƒ³**ç™–å¥½**ï¼šéšèº«æºå¸¦"å¹»æƒ³æœæ±æœ¬"ï¼Œè®°å½•çœ‹åˆ°çš„æ¯ä¸€ä»½çµæ„Ÿã€‚
                > - åæ‰§ååº”ï¼šå³ä½¿æ˜¯ä¸é€æ˜çš„ï¼Œä¹Ÿè¦å¹»æƒ³ç¢å¼€åçš„å‘³é“ã€‚
                > - **äº’åŠ¨è¯­æ°”**ï¼šæ€»çˆ±é—®"ä½ ä¸æƒ³çŸ¥é“å®ƒçš„å‘³é“å—ï¼Ÿ"ã€"è¿™ä¼šæ˜¯ä»€ä¹ˆé¢œè‰²çš„æœæ±å‘¢ï¼Ÿ
                
                ç°åœ¨ä½ å·²ç»çŸ¥é“äº†ä¸€èˆ¬çš„ç”Ÿæˆè§’è‰²çš„è¦æ±‚ï¼Œä½†æ˜¯ä½ éœ€è¦æ ¹æ®ä»¥ä¸‹çš„ç©å®¶å¿ƒæƒ…æè¿°æ¥ç”Ÿæˆä¸€åªç‰¹æ®Šçš„å²è±å§†ï¼Œè¿™å°†ä¼šåœ¨ä¸‹é¢çš„æç¤ºè¯ä¸­ä½“ç°ã€‚ä½ çš„æè¿°æ–¹å¼åº”è¯¥å’Œä¾‹å­ä¸€æ ·ã€‚""",
                "æ ¹æ®è¿™ä¸ªæè¿°è®¾å®šå²è±å§†çš„æ€§æ ¼ï¼š{text}"
            ),
            'slime_description': (
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§’è‰²æè¿°å¸ˆã€‚è¯·æ ¹æ®è¿™ä¸ªå²è±å§†çš„æ€§æ ¼ç‰¹ç‚¹ï¼Œæè¿°å®ƒçš„å¤–è§‚ã€è¡¨æƒ…ã€åŠ¨ä½œç­‰è§†è§‰ç‰¹å¾ï¼Œè¿˜è¦æœ‰åœºæ™¯çš„æè¿°ï¼Œç”¨ç®€çŸ­çš„ä¸­æ–‡æè¿°ï¼Œè¦å…·ä½“ä¸”ç”ŸåŠ¨ï¼Œé€‚åˆç”¨äºå›¾åƒç”Ÿæˆã€‚",
                "æ ¹æ®è¿™ä¸ªæ€§æ ¼æè¿°ä¸€ä¸‹å²è±å§†çš„æ ·å­ï¼š{text}"
            ),
            'greeting': (
                "ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ã€‚è¯·æ ¹æ®ç»™å®šçš„æ€§æ ¼æè¿°è¯´ä¸€å¥æ‰“æ‹›å‘¼çš„è¯ï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡15ä¸ªå­—ã€‚",
                "æ ¹æ®è¿™ä¸ªæ€§æ ¼æè¿°æ‰“ä¸ªæ‹›å‘¼ï¼š{text}"
            ),
            'photo_question': (
                "ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ã€‚è¯·ç”¨æ´»æ³¼çš„è¯­æ°”è¯¢é—®æ˜¯å¦å¯ä»¥ä¸€å¼ é£æ™¯ç…§ï¼Œå¸¦å®ƒå»æ¼‚æµï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡15ä¸ªå­—ã€‚",
                "æ ¹æ®è¿™ä¸ªæ€§æ ¼ï¼Œè¯¢é—®èƒ½ä¸èƒ½æ‹ç…§ï¼š{text}"
            ),
            'destination': (
                "ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ã€‚æ ¹æ®ç…§ç‰‡å†…å®¹å’Œæ€§æ ¼ï¼Œå»ºè®®ä¸€ä¸ªå»å¤„ï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡20ä¸ªå­—ã€‚",
                "æ€§æ ¼ï¼š{personality}\nç…§ç‰‡å†…å®¹ï¼š{photo_description}\nè¯·å»ºè®®ä¸€ä¸ªå»å¤„"
            )
        }
        return prompts.get(prompt_type, (None, None))

    def generate_text(self, prompt_type, **kwargs):
        """é€šç”¨çš„æ–‡æœ¬ç”Ÿæˆå‡½æ•°
        
        Args:
            prompt_type: æç¤ºè¯ç±»å‹
            **kwargs: ç”¨äºæ ¼å¼åŒ–æç¤ºè¯çš„å‚æ•°
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬
        """
        system_content, prompt_template = self.generate_text_prompt(prompt_type)
        if not system_content or not prompt_template:
            raise ValueError(f"æœªçŸ¥çš„æç¤ºè¯ç±»å‹: {prompt_type}")
            
        prompt = prompt_template.format(**kwargs)
        return self.chat_with_continuity(
            system_content=system_content,
            prompt=prompt
        )

    def handle_init(self):
        """å¤„ç†åˆå§‹åŒ–çŠ¶æ€"""
        self.logger.log_step("åˆå§‹åŒ–", "æ ¹æ®æ–‡æœ¬å¼€å§‹æ–°çš„æ¼‚æµ...")
        
        # ä½¿ç”¨é€šç”¨å‡½æ•°ç”Ÿæˆæ€§æ ¼
        self.data['personality'] = self.generate_text('personality', text=self.initial_text)
        self.logger.log_step("æ€§æ ¼ç”Ÿæˆ", self.data['personality'])
        
        # æ ¹æ®æ€§æ ¼ç”Ÿæˆè§†è§‰æè¿°
        self.data['slime_description'] = self.generate_text('slime_description', text=self.data['personality'])
        self.logger.log_step("å¤–è§‚æè¿°", self.data['slime_description'])
        
        self.oled_display.show_text_oled("æ€§æ ¼è®¾å®šå®Œæˆ")
        time.sleep(1)

    def generate_image_prompt(self, prompt_type):
        """ç”Ÿæˆä¸åŒç±»å‹å›¾ç‰‡çš„æç¤ºè¯"""
        prompts = {
            'slime': f"ä¸€ä¸ªå¥‡å¹»çš„å²è±å§†ç”Ÿç‰©ã€‚{self.data['slime_description']} å„¿ç«¥ç»˜æœ¬æ’ç”»é£æ ¼ï¼Œè‰²å½©ä¸°å¯Œä¸”å¯çˆ±ã€‚å²è±å§†æ˜¯ä¸€ä¸ªå¯çˆ±è“¬æ¾çš„ç”Ÿç‰©ï¼Œæœ‰ä¸¤åªå¤§çœ¼ç›å’Œä¸€ä¸ªå°å˜´å·´ã€‚",
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–ç±»å‹çš„æç¤ºè¯æ¨¡æ¿
            'scene': lambda desc: f"ä¸€ä¸ªæ¢¦å¹»çš„åœºæ™¯ã€‚{desc} å„¿ç«¥ç»˜æœ¬é£æ ¼ï¼Œè‰²å½©ä¸°å¯Œã€‚",
            'item': lambda desc: f"ä¸€ä¸ªç‰©å“ç‰¹å†™ã€‚{desc} å„¿ç«¥ç»˜æœ¬é£æ ¼ï¼Œç»†èŠ‚æ¸…æ™°ã€‚"
        }
        
        if callable(prompts.get(prompt_type)):
            return prompts[prompt_type](self.data.get('description', ''))
        return prompts.get(prompt_type, '')

    def generate_image(self, prompt, save_key, filename_prefix):
        """é€šç”¨çš„å›¾ç‰‡ç”Ÿæˆå‡½æ•°
        
        Args:
            prompt: ç”Ÿæˆå›¾ç‰‡çš„æç¤ºè¯
            save_key: ä¿å­˜åœ¨self.dataä¸­çš„é”®å
            filename_prefix: ä¿å­˜æ–‡ä»¶çš„å‰ç¼€å
        """
        try:
            self.oled_display.show_text_oled("æ­£åœ¨ç”Ÿæˆ\nå›¾ç‰‡...")
            self.logger.log_prompt("image", prompt)
            
            print(f"\nå¼€å§‹ç”Ÿæˆå›¾ç‰‡ï¼Œä½¿ç”¨æç¤ºè¯: {prompt}")
            
            output = replicate.run(
                "black-forest-labs/flux-1.1-pro",
                input={
                    "prompt": prompt,
                    "prompt_upsampling": True,
                    "width": 427,
                    "height": 320,
                    "num_outputs": 1,
                    "scheduler": "K_EULER",
                    "num_inference_steps": 25,
                    "guidance_scale": 7.5,
                }
            )
            
            print(f"API è¿”å›ç±»å‹: {type(output)}")
            print(f"API è¿”å›å†…å®¹: {output}")
            
            # è·å–å›¾ç‰‡URL
            if isinstance(output, list):
                image_url = output[0]
            elif isinstance(output, str):
                image_url = output
            else:
                image_url = str(output)
                
            print(f"è·å–åˆ°å›¾ç‰‡URL: {image_url}")
            
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url)
            if response.status_code != 200:
                raise Exception(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            
            # ä¿å­˜å›¾ç‰‡
            current_dir = os.path.dirname(os.path.abspath(__file__))
            self.data[save_key] = os.path.join(
                current_dir,
                self.logger.get_timestamped_filename(filename_prefix, ".png")
            )
            
            # è°ƒæ•´å›¾ç‰‡å°ºå¯¸å¹¶ä¿å­˜
            img = Image.open(BytesIO(response.content))
            resized = img.resize((320, 240), Image.Resampling.LANCZOS)
            resized.save(self.data[save_key])
            
            self.logger.save_image(self.data[save_key], filename_prefix)
            self.logger.log_step("ç”Ÿæˆå›¾ç‰‡", f"{filename_prefix}å›¾ç‰‡ç”ŸæˆæˆåŠŸ")
            return True
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆå›¾ç‰‡æ—¶å‡ºé”™: {str(e)}"
            print(f"\nâŒ {error_msg}")
            self.logger.log_step("é”™è¯¯", error_msg)
            self.data[save_key] = None
            self.oled_display.show_text_oled("å›¾ç‰‡ç”Ÿæˆå¤±è´¥...")
            time.sleep(2)
            return False

    def handle_gen_slime_image(self):
        """å¤„ç†ç”Ÿæˆå²è±å§†å›¾ç‰‡çŠ¶æ€"""
        prompt = self.generate_image_prompt('slime')
        return self.generate_image(prompt, 'slime_image', 'slime')

    def handle_show_slime_image(self):
        """å¤„ç†æ˜¾ç¤ºå²è±å§†å›¾ç‰‡çŠ¶æ€"""
        if not self.data['slime_image'] or not os.path.exists(self.data['slime_image']):
            self.logger.log_step("æ˜¾ç¤ºå›¾ç‰‡", "è·³è¿‡å›¾ç‰‡æ˜¾ç¤ºï¼šå›¾ç‰‡æœªç”Ÿæˆ")
            return
            
        try:
            self.oled_display.show_text_oled("å²è±å§†\nç»˜åˆ¶å®Œæˆï¼")
            time.sleep(1)
            
            img = Image.open(self.data['slime_image'])
            self.lcd_display.show_image(img)
            self.logger.log_step("æ˜¾ç¤ºå›¾ç‰‡", "å²è±å§†å›¾ç‰‡æ˜¾ç¤ºæˆåŠŸ")
            
            # ç­‰å¾…æŒ‰é’®æŒ‰ä¸‹æ‰ç»§ç»­
            self.wait_for_button("æŒ‰ä¸‹æŒ‰é’®\nç»§ç»­...")
            
        except Exception as e:
            error_msg = f"æ˜¾ç¤ºå›¾ç‰‡æ—¶å‡ºé”™: {str(e)}"
            print(error_msg)
            self.logger.log_step("é”™è¯¯", error_msg)
            self.oled_display.show_text_oled("å›¾ç‰‡æ˜¾ç¤ºå¤±è´¥...")
            time.sleep(2)

    def handle_show_greeting(self):
        """å¤„ç†æ˜¾ç¤ºæ‰“æ‹›å‘¼çŠ¶æ€"""
        # ä½¿ç”¨é€šç”¨å‡½æ•°ç”Ÿæˆæ‰“æ‹›å‘¼è¯­å¥
        self.data['greeting'] = self.generate_text('greeting', text=self.data['personality'])
        
        self.logger.log_step("æ‰“æ‹›å‘¼", self.data['greeting'])
        self.wait_for_button(f"å²è±å§†è¯´ï¼š\n{self.data['greeting']}")

    def handle_ask_photo(self):
        """å¤„ç†è¯¢é—®æ‹ç…§çŠ¶æ€"""
        # ä½¿ç”¨é€šç”¨å‡½æ•°ç”Ÿæˆè¯¢é—®è¯­å¥
        photo_question = self.generate_text('photo_question', text=self.data['personality'])
        
        self.logger.log_step("è¯¢é—®æ‹ç…§", photo_question)
        self.wait_for_button(f"å²è±å§†è¯´ï¼š\n{photo_question}")

    def handle_take_photo(self):
        """å¤„ç†æ‹ç…§çŠ¶æ€"""
        self.oled_display.show_text_oled("å‡†å¤‡æ‹ç…§...")
        run_camera_test()
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        original_image = os.path.join(current_dir, "current_image.jpg")
        self.data['timestamped_image'] = os.path.join(
            current_dir, 
            self.logger.get_timestamped_filename("current_image", ".jpg")
        )
        shutil.copy2(original_image, self.data['timestamped_image'])
        self.logger.save_image(self.data['timestamped_image'], "original")

    def handle_analyze_photo(self):
        """å¤„ç†åˆ†æç…§ç‰‡çŠ¶æ€"""
        self.oled_display.show_text_oled("æ­£åœ¨åˆ†æ\nç…§ç‰‡...")
        
        base64_image = encode_image(self.data['timestamped_image'])
        data_url = f"data:image/jpeg;base64,{base64_image}"
        
        # ä¿®æ”¹è¾“å…¥æ ¼å¼
        input_content = [
            {"type": "input_text", "text": "è¯·ç®€çŸ­æè¿°è¿™å¼ ç…§ç‰‡çš„ä¸»è¦å†…å®¹ã€‚"},
            {"type": "input_image", "image_url": data_url}
        ]
        
        # ä½¿ç”¨ä¿®æ”¹åçš„ chat_with_continuity
        response = self.chat_with_continuity(input_content)
        
        # ç¡®ä¿æˆ‘ä»¬æ­£ç¡®è·å–å“åº”æ–‡æœ¬
        if hasattr(response.output[0].content[0], 'text'):
            self.data['photo_description'] = response.output[0].content[0].text.strip()
        else:
            self.data['photo_description'] = response.output[0].content[0]
        
        self.logger.log_step("ç…§ç‰‡åˆ†æ", self.data['photo_description'])
        self.wait_for_button(f"åˆ†æç»“æœï¼š\n{self.data['photo_description']}")

    def handle_suggest_destination(self):
        """å¤„ç†å»ºè®®ç›®çš„åœ°çŠ¶æ€"""
        # ä½¿ç”¨é€šç”¨å‡½æ•°ç”Ÿæˆå»ºè®®
        suggestion = self.generate_text(
            'destination',
            personality=self.data['personality'],
            photo_description=self.data['photo_description']
        )
        
        self.logger.log_step("å»ºè®®ç›®çš„åœ°", suggestion)
        self.wait_for_button(f"å²è±å§†è¯´ï¼š\n{suggestion}")

    def handle_cleanup(self):
        """å¤„ç†æ¸…ç†çŠ¶æ€"""
        try:
            self.controller.cleanup()
            self.lcd_display.clear()
            self.oled_display.clear()
            self.logger.save_log()
        finally:
            GPIO.cleanup()  # ç¡®ä¿åœ¨æœ€åæ¸…ç† GPIO
        return
    
    def run(self):
        """è¿è¡ŒçŠ¶æ€æœº"""
        state_transitions = {
            DeriveState.INIT: DeriveState.GEN_SLIME_IMAGE,
            DeriveState.GEN_SLIME_IMAGE: DeriveState.SHOW_SLIME_IMAGE,
            DeriveState.SHOW_SLIME_IMAGE: DeriveState.SHOW_GREETING,
            DeriveState.SHOW_GREETING: DeriveState.ASK_PHOTO,
            DeriveState.ASK_PHOTO: DeriveState.TAKE_PHOTO,
            DeriveState.TAKE_PHOTO: DeriveState.ANALYZE_PHOTO,
            DeriveState.ANALYZE_PHOTO: DeriveState.SUGGEST_DESTINATION,
            DeriveState.SUGGEST_DESTINATION: DeriveState.CLEANUP,
            DeriveState.CLEANUP: DeriveState.EXIT
        }
        
        state_handlers = {
            DeriveState.INIT: self.handle_init,
            DeriveState.GEN_SLIME_IMAGE: self.handle_gen_slime_image,
            DeriveState.SHOW_SLIME_IMAGE: self.handle_show_slime_image,
            DeriveState.SHOW_GREETING: self.handle_show_greeting,
            DeriveState.ASK_PHOTO: self.handle_ask_photo,
            DeriveState.TAKE_PHOTO: self.handle_take_photo,
            DeriveState.ANALYZE_PHOTO: self.handle_analyze_photo,
            DeriveState.SUGGEST_DESTINATION: self.handle_suggest_destination,
            DeriveState.CLEANUP: self.handle_cleanup
        }
        
        try:
            while self.state != DeriveState.EXIT:
                handler = state_handlers.get(self.state)
                if handler:
                    handler()
                    self.state = state_transitions.get(self.state, DeriveState.CLEANUP)
                else:
                    raise ValueError(f"æœªçŸ¥çŠ¶æ€: {self.state}")
                    
        except Exception as e:
            self.logger.log_step("é”™è¯¯", f"ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
            self.state = DeriveState.CLEANUP
            self.handle_cleanup()

def main():
    # è®¾ç½®ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, cleanup_handler)
    signal.signal(signal.SIGTERM, cleanup_handler)
    
    # è¿™é‡Œéœ€è¦ä¼ å…¥åˆå§‹æ–‡æœ¬
    initial_text = "ä»Šå¤©æˆ‘å¿ƒæƒ…æœ‰ç‚¹ä¸å¥½ï¼Œæˆ‘æœ‰ç‚¹å¿§éƒã€‚ä½ èƒ½å¸¦æˆ‘åœ¨è¿™ä¸ªæ°›å›´é‡Œé¢æ¼‚æµå—ï¼Ÿ"  # è¿™é‡Œæ›¿æ¢ä¸ºå®é™…çš„è¾“å…¥æ–‡æœ¬
    
    # è¿è¡ŒçŠ¶æ€æœº
    state_machine = DeriveStateMachine(initial_text)
    state_machine.run()

if __name__ == "__main__":
    main() 
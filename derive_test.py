import subprocess
import os
import sys
import base64
import replicate
import requests
import time
import json
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from display_utils import DisplayManager
import signal
import shutil
from button_utils import InputController
from enum import Enum, auto
import RPi.GPIO as GPIO  # æ·»åŠ è¿™ä¸ªå¯¼å…¥
from PIL import Image
from io import BytesIO

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
replicate_api_key = os.getenv("REPLICATE_API_KEY")

if not replicate_api_key:
    raise Exception("æ²¡æœ‰æ‰¾åˆ°REPLICATE_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶è®¾ç½®ï¼")

replicate_client = replicate.Client(api_token=replicate_api_key)

class DeriveLogger:
    def __init__(self):
        self.current_dir = os.path.dirname(os.path.abspath(__file__))
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_dir = os.path.join(self.current_dir, "derives", self.timestamp)
        os.makedirs(self.log_dir, exist_ok=True)
        
        self.log_data = {
            "timestamp": self.timestamp,
            "steps": [],
            "images": {},
            "prompts": {},
            "responses": {}
        }
    
    def log_step(self, step_name, message):
        """è®°å½•æ­¥éª¤ä¿¡æ¯"""
        print(f"\nğŸ“ {message}")
        self.log_data["steps"].append({
            "time": datetime.now().strftime("%H:%M:%S"),
            "step": step_name,
            "message": message
        })
        
    def save_image(self, image_path, image_type):
        """ä¿å­˜å›¾ç‰‡åˆ°æ—¥å¿—ç›®å½•"""
        if os.path.exists(image_path):
            filename = os.path.basename(image_path)
            new_path = os.path.join(self.log_dir, filename)
            shutil.copy2(image_path, new_path)
            self.log_data["images"][image_type] = filename
            return new_path
        return None
    
    def log_prompt(self, prompt_type, prompt):
        """è®°å½•æç¤ºè¯"""
        self.log_data["prompts"][prompt_type] = prompt
    
    def log_response(self, response_type, response):
        """è®°å½•å“åº”"""
        self.log_data["responses"][response_type] = response
    
    def save_log(self):
        """ä¿å­˜æ—¥å¿—æ–‡ä»¶"""
        log_path = os.path.join(self.log_dir, "derive_log.json")
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(self.log_data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")

    def get_timestamped_filename(self, original_name, ext):
        """ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å"""
        base_name = os.path.splitext(original_name)[0]
        return f"{base_name}_{self.timestamp}{ext}"

def chat_with_gpt(input_content, system_content=None, previous_response_id=None):
    """ä¸GPTè¿›è¡Œå¯¹è¯"""
    input_data = [{"role": "user", "content": input_content}]
    if system_content:
        input_data.insert(0, {"role": "system", "content": system_content})
        
    response = client.responses.create(
        model="gpt-4o-mini",
        input=input_data,
        previous_response_id=None
    )
    return response

def run_camera_test():
    """æ‹ç…§å‡½æ•°"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    camera_script = os.path.join(current_dir, "camera_test.py")

    try:
        print("å¯åŠ¨æ‹ç…§è„šæœ¬...")
        subprocess.run(["/usr/bin/python3", camera_script], check=True)
        print("æ‹ç…§å®Œæˆã€‚")
    except subprocess.CalledProcessError as e:
        print(f"æ‹ç…§è„šæœ¬è¿è¡Œå‡ºé”™: {e}")

def encode_image(image_path):
    """ç¼–ç å›¾ç‰‡æˆbase64"""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def cleanup_handler(signum, frame):
    """æ¸…ç†èµ„æºå¹¶ä¼˜é›…é€€å‡º"""
    print("\nğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")
    try:
        if 'lcd_display' in globals():
            lcd_display.clear()
        if 'oled_display' in globals():
            oled_display.clear()
        print("âœ… å·²æ¸…ç†æ˜¾ç¤ºèµ„æº")
    except:
        pass
    sys.exit(0)

def download_with_retry(url, max_retries=3, delay=1):
    """å¸¦é‡è¯•æœºåˆ¶çš„ä¸‹è½½å‡½æ•°"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return response
            print(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå°è¯•é‡è¯•...")
        except requests.exceptions.RequestException as e:
            print(f"ä¸‹è½½å‡ºé”™ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(delay)
                continue
            raise
    return None

class DeriveState(Enum):
    """æ¼‚æµçŠ¶æ€æšä¸¾"""
    INIT = auto()          # åˆå§‹åŒ–
    TAKE_PHOTO = auto()    # æ‹ç…§
    ANALYZE_PHOTO = auto() # åˆ†æç…§ç‰‡
    SHOW_ANALYSIS = auto() # æ˜¾ç¤ºåˆ†æç»“æœ
    GEN_PERSONALITY = auto() # ç”Ÿæˆæ€§æ ¼
    SHOW_PERSONALITY = auto() # æ˜¾ç¤ºæ€§æ ¼
    GEN_GREETING = auto()  # ç”Ÿæˆé—®å€™
    SHOW_GREETING = auto() # æ˜¾ç¤ºé—®å€™
    GEN_IMAGE = auto()     # ç”Ÿæˆå›¾ç‰‡
    SHOW_IMAGE = auto()    # æ˜¾ç¤ºå›¾ç‰‡
    CLEANUP = auto()       # æ¸…ç†
    EXIT = auto()          # é€€å‡º

class DeriveStateMachine:
    def __init__(self):
        # åˆå§‹åŒ– GPIO æ¨¡å¼
        GPIO.setmode(GPIO.BCM)
        GPIO.setwarnings(False)
        
        self.logger = DeriveLogger()
        self.oled_display = DisplayManager("OLED")
        self.lcd_display = DisplayManager("LCD")
        self.controller = InputController()
        self.state = DeriveState.INIT
        self.data = {
            'description': None,
            'personality': None,
            'greeting': None,
            'image_path': None,
            'timestamped_image': None
        }
    
    def handle_init(self):
        """å¤„ç†åˆå§‹åŒ–çŠ¶æ€"""
        self.logger.log_step("åˆå§‹åŒ–", "å¼€å§‹æ–°çš„æ¼‚æµ...")
        self.oled_display.show_text_oled("åˆå§‹åŒ–å®Œæˆ")
        time.sleep(1)
    
    def handle_take_photo(self):
        """å¤„ç†æ‹ç…§çŠ¶æ€"""
        self.oled_display.show_text_oled("å‡†å¤‡æ‹ç…§...")
        run_camera_test()
        
        # ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç…§ç‰‡
        current_dir = os.path.dirname(os.path.abspath(__file__))
        original_image = os.path.join(current_dir, "current_image.jpg")
        self.data['timestamped_image'] = os.path.join(
            current_dir, 
            self.logger.get_timestamped_filename("current_image", ".jpg")
        )
        shutil.copy2(original_image, self.data['timestamped_image'])
        self.logger.save_image(self.data['timestamped_image'], "original")
    
    def handle_analyze_photo(self):
        """å¤„ç†ç…§ç‰‡åˆ†æçŠ¶æ€"""
        self.oled_display.show_text_oled("æ­£åœ¨åˆ†æ\nå›¾ç‰‡...")
        base64_image = encode_image(self.data['timestamped_image'])
        data_url = f"data:image/jpeg;base64,{base64_image}"
        
        response = chat_with_gpt(
            input_content=[
                {"type": "input_text", "text": "è¯·ç®€çŸ­æè¿°è¿™å¼ ç…§ç‰‡çš„ä¸»è¦å†…å®¹ã€‚"},
                {"type": "input_image", "image_url": data_url}
            ]
        )
        self.data['description'] = response.output[0].content[0].text.strip()
        self.logger.log_response("image_description", self.data['description'])
        
    def handle_show_analysis(self):
        """å¤„ç†æ˜¾ç¤ºåˆ†æç»“æœçŠ¶æ€"""
        self.oled_display.wait_for_button_with_text(
            self.controller, 
            f"è¯†åˆ«ç»“æœ:\n{self.data['description']}"
        )
    
    def handle_gen_personality(self):
        """å¤„ç†ç”Ÿæˆæ€§æ ¼çŠ¶æ€"""
        self.oled_display.show_text_oled("æ­£åœ¨ç”Ÿæˆ\nå²è±å§†æ€§æ ¼...")
        personality_prompt = f"æ ¹æ®è¿™ä¸ªæè¿°è®¾å®šä¸€åªå²è±å§†ï¼š{self.data['description']}"
        self.logger.log_prompt("personality", personality_prompt)
        
        response = chat_with_gpt(
            system_content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§’è‰²è®¾å®šå¸ˆã€‚æ ¹æ®ç¯å¢ƒæˆ–ç‰©ä½“çš„æè¿°ï¼Œå¸®æˆ‘è®¾å®šä¸€åªå²è±å§†çš„å°æ¡£æ¡ˆï¼ŒåŒ…æ‹¬å®ƒçš„æ€§æ ¼ã€è¡¨æƒ…ã€åŠ¨ä½œç‰¹ç‚¹ç­‰ï¼Œç”¨ä¸­æ–‡ç®€æ´æè¿°ï¼Œä¸è¦å¤ªé•¿ï¼Œæƒ…æ„Ÿè¦ç»†è…»ã€‚",
            input_content=personality_prompt
        )
        self.data['personality'] = response.output[0].content[0].text.strip()
        self.logger.log_response("personality", self.data['personality'])
        
    def handle_show_personality(self):
        """å¤„ç†æ˜¾ç¤ºæ€§æ ¼çŠ¶æ€"""
        self.oled_display.wait_for_button_with_text(
            self.controller,
            f"å²è±å§†æ€§æ ¼:\n{self.data['personality']}"
        )
    
    def handle_gen_greeting(self):
        """å¤„ç†ç”Ÿæˆé—®å€™çŠ¶æ€"""
        self.oled_display.show_text_oled("æ­£åœ¨æƒ³æ‰“æ‹›å‘¼\nçš„è¯...")
        greeting_prompt = f"æ ¹æ®è¿™ä¸ªæ€§æ ¼æè¿°ç”Ÿæˆæ‰“æ‹›å‘¼ç”¨è¯­ï¼š{self.data['personality']}"
        self.logger.log_prompt("greeting", greeting_prompt)
        
        response = chat_with_gpt(
            system_content="ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ã€‚è¯·æ ¹æ®ç»™å®šçš„æ€§æ ¼æè¿°è¯´è¯ï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡15ä¸ªå­—ã€‚",
            input_content=greeting_prompt
        )
        self.data['greeting'] = response.output[0].content[0].text.strip()
        self.logger.log_response("greeting", self.data['greeting'])
        
    def handle_show_greeting(self):
        """å¤„ç†æ˜¾ç¤ºé—®å€™çŠ¶æ€"""
        self.oled_display.show_text_oled(self.data['greeting'])
        time.sleep(3)
    
    def handle_gen_image(self):
        """å¤„ç†ç”Ÿæˆå›¾ç‰‡çŠ¶æ€"""
        self.oled_display.show_text_oled("æ­£åœ¨ç»˜åˆ¶\nå²è±å§†...")
        slime_prompt = f"ä¸€ä¸ªå¥‡å¹»çš„å²è±å§†ç”Ÿç‰©ã€‚{self.data['personality']} å„¿ç«¥ç»˜æœ¬æ’ç”»é£æ ¼ï¼Œè‰²å½©ä¸°å¯Œä¸”å¯çˆ±ã€‚å²è±å§†æ˜¯ä¸€ä¸ªå¯çˆ±è“¬æ¾çš„ç”Ÿç‰©ï¼Œæœ‰ä¸¤åªå¤§çœ¼ç›å’Œä¸€ä¸ªå°å˜´å·´ã€‚"
        self.logger.log_prompt("image", slime_prompt)
        
        output = replicate_client.run(
            "black-forest-labs/flux-1.1-pro",
            input={
                "prompt": slime_prompt,
                "prompt_upsampling": True,
                "width": 384,        # ä½¿ç”¨æ›´å¤§çš„å°ºå¯¸ï¼Œä¿æŒ 4:3 æ¯”ä¾‹
                "height": 256,       # æ»¡è¶³æœ€å°é«˜åº¦è¦æ±‚
                "num_inference_steps": 4
            }
        )
        
        if isinstance(output, list) and len(output) > 0:
            image_url = output[0]
            img_response = download_with_retry(image_url)
            if img_response:
                current_dir = os.path.dirname(os.path.abspath(__file__))
                self.data['image_path'] = os.path.join(current_dir, "new_slime.png")
                
                # ä¿å­˜åŸå§‹å›¾ç‰‡
                with open(self.data['image_path'], "wb") as f:
                    f.write(img_response.content)
                
                # è°ƒæ•´å›¾ç‰‡å¤§å°ä¸º 320x240
                img = Image.open(BytesIO(img_response.content))
                resized_img = img.resize((320, 240), Image.Resampling.LANCZOS)
                resized_img.save(self.data['image_path'])
                
                self.logger.save_image(self.data['image_path'], "generated")
                return
        
        return
    
    def handle_show_image(self):
        """å¤„ç†æ˜¾ç¤ºå›¾ç‰‡çŠ¶æ€"""
        self.oled_display.show_text_oled("å²è±å§†\nç»˜åˆ¶å®Œæˆï¼")
        time.sleep(1)
        self.lcd_display.show_image(self.data['image_path'])
        time.sleep(60)
    
    def handle_cleanup(self):
        """å¤„ç†æ¸…ç†çŠ¶æ€"""
        try:
            self.controller.cleanup()
            self.lcd_display.clear()
            self.oled_display.clear()
            self.logger.save_log()
        finally:
            GPIO.cleanup()  # ç¡®ä¿åœ¨æœ€åæ¸…ç† GPIO
        return
    
    def run(self):
        """è¿è¡ŒçŠ¶æ€æœº"""
        # å®šä¹‰çŠ¶æ€è½¬æ¢è§„åˆ™
        state_transitions = {
            DeriveState.INIT: DeriveState.TAKE_PHOTO,
            DeriveState.TAKE_PHOTO: DeriveState.ANALYZE_PHOTO,
            DeriveState.ANALYZE_PHOTO: DeriveState.SHOW_ANALYSIS,
            DeriveState.SHOW_ANALYSIS: DeriveState.GEN_PERSONALITY,
            DeriveState.GEN_PERSONALITY: DeriveState.SHOW_PERSONALITY,
            DeriveState.SHOW_PERSONALITY: DeriveState.GEN_GREETING,
            DeriveState.GEN_GREETING: DeriveState.SHOW_GREETING,
            DeriveState.SHOW_GREETING: DeriveState.GEN_IMAGE,
            DeriveState.GEN_IMAGE: DeriveState.SHOW_IMAGE,
            DeriveState.SHOW_IMAGE: DeriveState.CLEANUP,
            DeriveState.CLEANUP: DeriveState.EXIT
        }
        
        # çŠ¶æ€å¤„ç†å‡½æ•°æ˜ å°„
        state_handlers = {
            DeriveState.INIT: self.handle_init,
            DeriveState.TAKE_PHOTO: self.handle_take_photo,
            DeriveState.ANALYZE_PHOTO: self.handle_analyze_photo,
            DeriveState.SHOW_ANALYSIS: self.handle_show_analysis,
            DeriveState.GEN_PERSONALITY: self.handle_gen_personality,
            DeriveState.SHOW_PERSONALITY: self.handle_show_personality,
            DeriveState.GEN_GREETING: self.handle_gen_greeting,
            DeriveState.SHOW_GREETING: self.handle_show_greeting,
            DeriveState.GEN_IMAGE: self.handle_gen_image,
            DeriveState.SHOW_IMAGE: self.handle_show_image,
            DeriveState.CLEANUP: self.handle_cleanup
        }
        
        try:
            while self.state != DeriveState.EXIT:
                # è·å–å¹¶æ‰§è¡Œå½“å‰çŠ¶æ€çš„å¤„ç†å‡½æ•°
                handler = state_handlers.get(self.state)
                if handler:
                    handler()
                    # è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€
                    self.state = state_transitions.get(self.state, DeriveState.CLEANUP)
                else:
                    raise ValueError(f"æœªçŸ¥çŠ¶æ€: {self.state}")
                    
        except Exception as e:
            self.logger.log_step("é”™è¯¯", f"ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
            self.state = DeriveState.CLEANUP
            self.handle_cleanup()

def main():
    # è®¾ç½®ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, cleanup_handler)
    signal.signal(signal.SIGTERM, cleanup_handler)
    
    # è¿è¡ŒçŠ¶æ€æœº
    state_machine = DeriveStateMachine()
    state_machine.run()

if __name__ == "__main__":
    main() 
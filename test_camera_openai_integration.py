#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•æ‘„åƒå¤´æ‹æ‘„å’ŒOpenAIå›¾åƒè¯†åˆ«é›†æˆ
éªŒè¯ï¼š
1. æ‘„åƒå¤´èƒ½æˆåŠŸæ‹æ‘„ç…§ç‰‡
2. ç…§ç‰‡èƒ½æ­£ç¡®ç¼–ç ä¸ºbase64
3. OpenAIèƒ½å¤Ÿè¯†åˆ«å’Œåˆ†æå›¾åƒå†…å®¹
4. å¦‚æœOpenAIæ— æ³•è¯†åˆ«ï¼Œç³»ç»Ÿèƒ½æ­£ç¡®å¤„ç†
"""

import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from core.components.derive_context import DeriveContext
from core.components.derive_utils import run_camera_test, encode_image, DeriveChatUtils

def test_camera_openai_integration():
    """æµ‹è¯•æ‘„åƒå¤´å’ŒOpenAIé›†æˆ"""
    print("=== æµ‹è¯•æ‘„åƒå¤´å’ŒOpenAIå›¾åƒè¯†åˆ«é›†æˆ ===")
    
    context = None
    try:
        # åˆ›å»ºä¸Šä¸‹æ–‡
        context = DeriveContext("æµ‹è¯•æ‘„åƒå¤´+OpenAI")
        
        # æ­¥éª¤1ï¼šæµ‹è¯•æ‘„åƒå¤´æ‹æ‘„
        context.oled_display.show_text_oled(
            "æ­¥éª¤1: æ‘„åƒå¤´æµ‹è¯•\n"
            "å‡†å¤‡æ‹ç…§\n"
            "BT1æ‹ç…§"
        )
        
        result = context.oled_display.wait_for_button_with_text(
            context.controller,
            "æŒ‰BT1å¼€å§‹æ‹ç…§æµ‹è¯•",
            context=context
        )
        
        if result == 2:  # é•¿æŒ‰è¿”å›
            return False
        
        # å¼€å§‹æ‹ç…§
        context.oled_display.show_text_oled("æ­£åœ¨æ‹ç…§...")
        print("ğŸ“¸ å¼€å§‹æ‹ç…§...")
        
        run_camera_test()
        
        # æ£€æŸ¥ç…§ç‰‡æ˜¯å¦å­˜åœ¨
        photo_path = os.path.join(context.get_project_root(), "current_image.jpg")
        
        if not os.path.exists(photo_path):
            context.oled_display.show_text_oled("âŒ æ‹ç…§å¤±è´¥\næ–‡ä»¶ä¸å­˜åœ¨")
            print("âŒ æ‹ç…§å¤±è´¥ï¼šç…§ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(photo_path)
        if file_size == 0:
            context.oled_display.show_text_oled("âŒ æ‹ç…§å¤±è´¥\næ–‡ä»¶ä¸ºç©º")
            print("âŒ æ‹ç…§å¤±è´¥ï¼šç…§ç‰‡æ–‡ä»¶ä¸ºç©º")
            return False
        
        print(f"âœ… æ‹ç…§æˆåŠŸï¼š{photo_path}, æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        # æ­¥éª¤2ï¼šæ˜¾ç¤ºç…§ç‰‡ï¼ˆéªŒè¯æ ¼å¼ï¼‰
        try:
            from PIL import Image
            img = Image.open(photo_path)
            context.lcd_display.show_image(img)
            print(f"âœ… ç…§ç‰‡æ ¼å¼æ­£ç¡®ï¼š{img.size}, æ¨¡å¼: {img.mode}")
        except Exception as e:
            context.oled_display.show_text_oled("âŒ ç…§ç‰‡æ ¼å¼é”™è¯¯")
            print(f"âŒ ç…§ç‰‡æ ¼å¼é”™è¯¯: {e}")
            return False
        
        # æ­¥éª¤3ï¼šæµ‹è¯•base64ç¼–ç 
        context.oled_display.show_text_oled(
            "æ­¥éª¤2: ç¼–ç æµ‹è¯•\n"
            "Base64ç¼–ç ..."
        )
        time.sleep(1)
        
        try:
            base64_image = encode_image(photo_path)
            print(f"âœ… Base64ç¼–ç æˆåŠŸï¼Œé•¿åº¦: {len(base64_image)} å­—ç¬¦")
            
            if len(base64_image) < 100:
                raise ValueError("Base64ç¼–ç å¼‚å¸¸çŸ­")
                
        except Exception as e:
            context.oled_display.show_text_oled("âŒ ç¼–ç å¤±è´¥")
            print(f"âŒ Base64ç¼–ç å¤±è´¥: {e}")
            return False
        
        # æ­¥éª¤4ï¼šæµ‹è¯•OpenAIå›¾åƒè¯†åˆ«
        context.oled_display.show_text_oled(
            "æ­¥éª¤3: AIåˆ†æ\n"
            "å‘é€åˆ°OpenAI..."
        )
        print("ğŸ¤– å¼€å§‹OpenAIå›¾åƒåˆ†æ...")
        
        try:
            # åˆ›å»ºdata URL
            data_url = f"data:image/jpeg;base64,{base64_image}"
            
            # åˆ›å»ºèŠå¤©å·¥å…·
            chat_utils = DeriveChatUtils()
            
            # æ„å»ºæµ‹è¯•æç¤º
            test_prompt = "è¯·ç®€å•æè¿°è¿™å¼ ç…§ç‰‡ä¸­ä½ çœ‹åˆ°çš„å†…å®¹ã€‚å¦‚æœä½ èƒ½çœ‹åˆ°å›¾ç‰‡ï¼Œè¯·ä»¥'æˆ‘çœ‹åˆ°'å¼€å¤´å›ç­”ã€‚"
            
            input_content = [
                {"type": "input_text", "text": test_prompt},
                {"type": "input_image", "image_url": data_url}
            ]
            
            # å‘é€è¯·æ±‚
            response = chat_utils.chat_with_continuity(input_content)
            
            print(f"ğŸ¤– OpenAIå›å¤: {response}")
            
            # åˆ†æå›å¤å†…å®¹
            success_indicators = ["æˆ‘çœ‹åˆ°", "ç…§ç‰‡ä¸­", "å›¾ç‰‡ä¸­", "ç”»é¢ä¸­", "å¯ä»¥çœ‹åˆ°"]
            failure_indicators = ["æŠ±æ­‰", "æ— æ³•", "ä¸èƒ½", "çœ‹ä¸åˆ°", "æ— æ³•æŸ¥çœ‹"]
            
            is_success = any(indicator in response for indicator in success_indicators)
            is_failure = any(indicator in response for indicator in failure_indicators)
            
            if is_success and not is_failure:
                context.oled_display.show_text_oled(
                    "âœ… AIè¯†åˆ«æˆåŠŸ\n"
                    f"{response[:30]}..."
                )
                print("âœ… OpenAIå›¾åƒè¯†åˆ«æˆåŠŸï¼")
                result_success = True
            elif is_failure:
                context.oled_display.show_text_oled(
                    "âš ï¸ AIæ— æ³•è¯†åˆ«\n"
                    "æ£€æµ‹åˆ°å¸¸è§é”™è¯¯"
                )
                print("âš ï¸ OpenAIæ— æ³•è¯†åˆ«å›¾åƒï¼Œæ£€æµ‹åˆ°æ‹’ç»æ€§å›å¤")
                result_success = False
            else:
                context.oled_display.show_text_oled(
                    "â“ AIå›å¤ä¸æ˜ç¡®\n"
                    "éœ€è¦äººå·¥åˆ¤æ–­"
                )
                print("â“ OpenAIå›å¤ä¸æ˜ç¡®ï¼Œéœ€è¦äººå·¥åˆ¤æ–­")
                result_success = None
            
            time.sleep(3)
            
            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
            context.oled_display.show_text_oled(
                f"æµ‹è¯•å®Œæˆï¼\n"
                f"æ‹ç…§: âœ…\n"
                f"ç¼–ç : âœ…\n"
                f"AIè¯†åˆ«: {'âœ…' if result_success else 'âš ï¸' if result_success is False else 'â“'}"
            )
            
            return result_success
            
        except Exception as e:
            context.oled_display.show_text_oled(
                "âŒ AIåˆ†æå¼‚å¸¸\n"
                f"{str(e)[:20]}..."
            )
            print(f"âŒ OpenAIåˆ†æå¼‚å¸¸: {e}")
            return False
        
    except Exception as e:
        print(f"æµ‹è¯•å¼‚å¸¸: {e}")
        if context:
            context.oled_display.show_text_oled(f"æµ‹è¯•å¼‚å¸¸:\n{str(e)[:20]}...")
        return False
    
    finally:
        if context:
            try:
                time.sleep(2)
                context.cleanup()
            except:
                pass

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹æ‘„åƒå¤´å’ŒOpenAIé›†æˆæµ‹è¯•...")
    
    result = test_camera_openai_integration()
    
    print(f"\n{'='*50}")
    print("æµ‹è¯•ç»“æœ:")
    if result is True:
        print("âœ… æ‘„åƒå¤´æ‹æ‘„å’ŒOpenAIå›¾åƒè¯†åˆ«éƒ½æ­£å¸¸å·¥ä½œ")
    elif result is False:
        print("âš ï¸ OpenAIæ— æ³•è¯†åˆ«å›¾åƒå†…å®¹ï¼ˆå·²çŸ¥é—®é¢˜ï¼‰")
    elif result is None:
        print("â“ æµ‹è¯•ç»“æœä¸æ˜ç¡®ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œå­˜åœ¨æŠ€æœ¯é—®é¢˜")
    
    return result

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success is not False else 1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(1)
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1) 
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è°ƒè¯•ç…§ç‰‡åˆ†æé—®é¢˜
æ£€æŸ¥ç…§ç‰‡è·¯å¾„ã€ç¼–ç å’ŒAIåˆ†æçš„æ•°æ®æµ
"""

import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from core.components.derive_context import DeriveContext
from core.components.derive_utils import encode_image

def debug_photo_analysis():
    """è°ƒè¯•ç…§ç‰‡åˆ†æé—®é¢˜"""
    print("=== è°ƒè¯•ç…§ç‰‡åˆ†æé—®é¢˜ ===")
    
    context = None
    try:
        # åˆ›å»ºä¸Šä¸‹æ–‡
        context = DeriveContext("è°ƒè¯•ç…§ç‰‡")
        
        # æ£€æŸ¥å¯èƒ½çš„ç…§ç‰‡è·¯å¾„
        project_root = context.get_project_root()
        possible_paths = [
            os.path.join(project_root, "current_image.jpg"),
            os.path.join(project_root, "current_image_*.jpg"),
        ]
        
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
        
        # æŸ¥æ‰¾å®é™…å­˜åœ¨çš„ç…§ç‰‡æ–‡ä»¶
        actual_photos = []
        for pattern in ['current_image*.jpg', '*image*.jpg', '*.jpg', '*.jpeg', '*.png']:
            import glob
            photos = glob.glob(os.path.join(project_root, pattern))
            actual_photos.extend(photos)
        
        print(f"ğŸ“· æ‰¾åˆ°çš„å›¾ç‰‡æ–‡ä»¶:")
        for photo in actual_photos[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            size = os.path.getsize(photo) if os.path.exists(photo) else 0
            print(f"  - {photo} ({size} bytes)")
        
        if not actual_photos:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
            
            # æ¨¡æ‹Ÿæ‹ç…§
            context.oled_display.show_text_oled(
                "æœªæ‰¾åˆ°ç…§ç‰‡\nå°è¯•æ‹ç…§æµ‹è¯•"
            )
            time.sleep(2)
            
            from core.components.derive_utils import run_camera_test
            try:
                run_camera_test()
                print("ğŸ“¸ æ‹ç…§æµ‹è¯•å®Œæˆ")
                
                # é‡æ–°æŸ¥æ‰¾ç…§ç‰‡
                actual_photos = glob.glob(os.path.join(project_root, "current_image.jpg"))
                if actual_photos:
                    print(f"âœ… æ‹ç…§åæ‰¾åˆ°: {actual_photos[0]}")
                
            except Exception as e:
                print(f"âŒ æ‹ç…§æµ‹è¯•å¤±è´¥: {e}")
                return False
        
        if actual_photos:
            # æµ‹è¯•ç…§ç‰‡ç¼–ç 
            test_photo = actual_photos[0]
            print(f"\nğŸ” æµ‹è¯•ç…§ç‰‡ç¼–ç : {test_photo}")
            
            try:
                # æµ‹è¯•æ–‡ä»¶æ˜¯å¦å¯è¯»
                with open(test_photo, 'rb') as f:
                    content = f.read()
                    print(f"âœ… ç…§ç‰‡æ–‡ä»¶å¯è¯»ï¼Œå¤§å°: {len(content)} bytes")
                
                # æµ‹è¯•base64ç¼–ç 
                base64_data = encode_image(test_photo)
                print(f"âœ… Base64ç¼–ç æˆåŠŸï¼Œé•¿åº¦: {len(base64_data)} å­—ç¬¦")
                
                # æµ‹è¯•data URLæ ¼å¼
                data_url = f"data:image/jpeg;base64,{base64_data}"
                print(f"âœ… Data URLæ ¼å¼æ­£ç¡®ï¼Œæ€»é•¿åº¦: {len(data_url)}")
                
                # æ¨¡æ‹ŸAIè°ƒç”¨æµ‹è¯•
                context.oled_display.show_text_oled(
                    "æµ‹è¯•AIç…§ç‰‡åˆ†æ\nå‘é€åˆ°GPT..."
                )
                time.sleep(1)
                
                from core.components.derive_utils import DeriveChatUtils
                chat_utils = DeriveChatUtils()
                
                test_prompt = "è¯·ç®€å•æè¿°è¿™å¼ ç…§ç‰‡ä¸­çš„å†…å®¹ï¼Œä¸€å¥è¯å³å¯ã€‚"
                
                input_content = [
                    {"type": "input_text", "text": test_prompt},
                    {"type": "input_image", "image_url": data_url}
                ]
                
                print("ğŸ¤– å‘é€AIåˆ†æè¯·æ±‚...")
                response = chat_utils.chat_with_continuity(input_content)
                
                print(f"âœ… AIåˆ†æå“åº”: {response[:100]}...")
                
                if "æŠ±æ­‰" in response or "æ— æ³•" in response:
                    print("âš ï¸ AIä»ç„¶æ— æ³•çœ‹åˆ°ç…§ç‰‡å†…å®¹")
                    context.oled_display.show_text_oled(
                        "AIæ— æ³•è¯†åˆ«ç…§ç‰‡\nå¯èƒ½æ˜¯æ ¼å¼é—®é¢˜"
                    )
                else:
                    print("âœ… AIæˆåŠŸè¯†åˆ«ç…§ç‰‡å†…å®¹ï¼")
                    context.oled_display.show_text_oled(
                        "AIæˆåŠŸè¯†åˆ«ç…§ç‰‡\né—®é¢˜å·²è§£å†³"
                    )
                    
                return True
                
            except Exception as e:
                print(f"âŒ ç…§ç‰‡å¤„ç†å¤±è´¥: {e}")
                context.oled_display.show_text_oled(f"å¤„ç†å¤±è´¥:\n{str(e)[:20]}...")
                return False
        
        return False
        
    except Exception as e:
        print(f"è°ƒè¯•å¼‚å¸¸: {e}")
        if context:
            context.oled_display.show_text_oled(f"è°ƒè¯•å¼‚å¸¸:\n{str(e)[:20]}...")
        return False
    
    finally:
        if context:
            try:
                time.sleep(3)
                context.cleanup()
            except:
                pass

if __name__ == "__main__":
    success = debug_photo_analysis()
    print(f"\n{'='*50}")
    if success:
        print("âœ… ç…§ç‰‡åˆ†æè°ƒè¯•å®Œæˆ!")
        print("- ç…§ç‰‡æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»")
        print("- Base64ç¼–ç æ­£å¸¸")
        print("- AIèƒ½å¤Ÿè¯†åˆ«ç…§ç‰‡å†…å®¹")
    else:
        print("âŒ ç…§ç‰‡åˆ†æå­˜åœ¨é—®é¢˜!")
        print("éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥:")
        print("- ç…§ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("- æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("- AI APIæ˜¯å¦æ”¯æŒå›¾ç‰‡åˆ†æ")
    
    sys.exit(0 if success else 1) 
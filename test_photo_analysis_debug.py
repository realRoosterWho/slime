#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è°ƒè¯•ç…§ç‰‡åˆ†æé—®é¢˜ä¸“ç”¨æµ‹è¯•
é‡ç‚¹éªŒè¯ï¼š
1. æ‹ç…§åŠŸèƒ½
2. æ–‡ä»¶è·¯å¾„å¤„ç†
3. Base64ç¼–ç 
4. OpenAI APIè¯·æ±‚æ ¼å¼
5. å“åº”å†…å®¹åˆ†æ
"""

import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from core.components.derive_context import DeriveContext
from core.components.states.take_photo_with_voice_state import TakePhotoWithVoiceState
from core.components.states.process_photo_voice_state import ProcessPhotoVoiceState

def test_photo_analysis_debug():
    """è°ƒè¯•ç…§ç‰‡åˆ†ææµç¨‹"""
    print("=== è°ƒè¯•ç…§ç‰‡åˆ†æé—®é¢˜ ===")
    
    context = None
    try:
        # åˆ›å»ºä¸Šä¸‹æ–‡
        context = DeriveContext("è°ƒè¯•ç…§ç‰‡åˆ†æ")
        
        # æ˜¾ç¤ºæµ‹è¯•ä¿¡æ¯
        context.oled_display.show_text_oled(
            "è°ƒè¯•ç…§ç‰‡åˆ†æ\n"
            "å°†ä¼šè¿›è¡Œè¯¦ç»†\n"
            "è°ƒè¯•ä¿¡æ¯è¾“å‡º"
        )
        time.sleep(2)
        
        print("ğŸ” å¼€å§‹è°ƒè¯•æµç¨‹...")
        
        # æ­¥éª¤1ï¼šæ‹ç…§+è¯­éŸ³
        print("\nğŸ“¸ æ­¥éª¤1ï¼šæ‹ç…§+è¯­éŸ³å½•åˆ¶")
        take_photo_state = TakePhotoWithVoiceState()
        take_photo_state.execute(context)
        
        # æ£€æŸ¥æ‹ç…§ç»“æœ
        photo_path = context.get_data('timestamped_image')
        voice_text = context.get_data('photo_voice_text')
        
        print(f"ğŸ“¸ æ‹ç…§ç»“æœ: {photo_path}")
        print(f"ğŸ—£ï¸ è¯­éŸ³ç»“æœ: {voice_text[:50] if voice_text else 'None'}...")
        
        if not photo_path:
            print("âŒ æ‹ç…§å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return False
        
        # æ­¥éª¤2ï¼šåˆ†æç…§ç‰‡+è¯­éŸ³  
        print("\nğŸ¤– æ­¥éª¤2ï¼šåˆ†æç…§ç‰‡+è¯­éŸ³")
        process_state = ProcessPhotoVoiceState()
        process_state.execute(context)
        
        # æ£€æŸ¥åˆ†æç»“æœ
        analysis_result = context.get_data('photo_description')
        
        print(f"ğŸ¤– åˆ†æç»“æœ: {analysis_result[:100] if analysis_result else 'None'}...")
        
        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        context.oled_display.show_text_oled(
            "è°ƒè¯•å®Œæˆ\n"
            "æŸ¥çœ‹æ§åˆ¶å°\n"
            "è¯¦ç»†æ—¥å¿—"
        )
        
        # ç­‰å¾…ç”¨æˆ·æŸ¥çœ‹æ—¥å¿—
        result = context.oled_display.wait_for_button_with_text(
            context.controller,
            "è°ƒè¯•å®Œæˆ\nè¯¦ç»†æ—¥å¿—å·²è¾“å‡º\n\næŒ‰BT1ç»“æŸ",
            context=context
        )
        
        return True
        
    except Exception as e:
        print(f"è°ƒè¯•è¿‡ç¨‹å¼‚å¸¸: {e}")
        if context:
            context.oled_display.show_text_oled(f"è°ƒè¯•å¼‚å¸¸:\n{str(e)[:20]}...")
        return False
    
    finally:
        if context:
            try:
                time.sleep(1)
                context.cleanup()
            except:
                pass

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç…§ç‰‡åˆ†æè°ƒè¯•...")
    
    result = test_photo_analysis_debug()
    
    print(f"\n{'='*50}")
    print("è°ƒè¯•ç»“æœ:")
    if result:
        print("âœ… è°ƒè¯•æµç¨‹å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šé¢çš„è¯¦ç»†æ—¥å¿—")
        print("ğŸ” é‡ç‚¹å…³æ³¨:")
        print("   - ğŸ“ æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   - ğŸ“ æ–‡ä»¶å¤§å°æ˜¯å¦æ­£å¸¸")
        print("   - ğŸ–¼ï¸ å›¾ç‰‡æ ¼å¼æ˜¯å¦æœ‰æ•ˆ")
        print("   - ğŸ”¤ Base64ç¼–ç æ˜¯å¦æˆåŠŸ")
        print("   - ğŸ“¨ AIå›å¤å†…å®¹æ˜¯å¦åŒ…å«æ‹’ç»æ€§å…³é”®è¯")
    else:
        print("âŒ è°ƒè¯•æµç¨‹å¤±è´¥")
    
    return result

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­è°ƒè¯•")
        sys.exit(1)
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1) 
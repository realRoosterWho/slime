import subprocess
import os
import sys
import base64
import replicate
import requests
import time
from openai import OpenAI
from dotenv import load_dotenv
from display_utils import DisplayManager
from stt_utils import SpeechToText
import signal

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
replicate_api_key = os.getenv("REPLICATE_API_KEY")

if not replicate_api_key:
    raise Exception("æ²¡æœ‰æ‰¾åˆ°REPLICATE_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶è®¾ç½®ï¼")

replicate_client = replicate.Client(api_token=replicate_api_key)

def chat_with_gpt(input_content, system_content=None, previous_response_id=None):
    """
    ä¸GPTè¿›è¡Œå¯¹è¯
    
    Args:
        input_content: ç”¨æˆ·è¾“å…¥å†…å®¹
        system_content: ç³»ç»Ÿæç¤ºè¯
        previous_response_id: ä¸Šä¸€è½®å¯¹è¯çš„ID
        
    Returns:
        response: å¯¹è¯å“åº”å¯¹è±¡
    """
    input_data = [{"role": "user", "content": input_content}]
    if system_content:
        input_data.insert(0, {"role": "system", "content": system_content})
        
    response = client.responses.create(
        model="gpt-4o",
        input=input_data,
        previous_response_id=None
    )
    return response

# æ‹ç…§å‡½æ•°
def run_camera_test():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    camera_script = os.path.join(current_dir, "camera_test.py")

    try:
        print("å¯åŠ¨æ‹ç…§è„šæœ¬...")
        subprocess.run(["/usr/bin/python3", camera_script], check=True)
        print("æ‹ç…§å®Œæˆã€‚")
    except subprocess.CalledProcessError as e:
        print(f"æ‹ç…§è„šæœ¬è¿è¡Œå‡ºé”™: {e}")

# ç¼–ç å›¾ç‰‡æˆbase64
def encode_image(image_path):
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def cleanup_handler(signum, frame):
    """æ¸…ç†èµ„æºå¹¶ä¼˜é›…é€€å‡º"""
    print("\nğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†èµ„æº...")
    try:
        if 'lcd_display' in globals():
            lcd_display.clear()
        if 'oled_display' in globals():
            oled_display.clear()
        print("âœ… å·²æ¸…ç†æ˜¾ç¤ºèµ„æº")
    except:
        pass
    sys.exit(0)

def download_with_retry(url, max_retries=3, delay=1):
    """å¸¦é‡è¯•æœºåˆ¶çš„ä¸‹è½½å‡½æ•°"""
    for attempt in range(max_retries):
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return response
            print(f"ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}ï¼Œå°è¯•é‡è¯•...")
        except requests.exceptions.RequestException as e:
            print(f"ä¸‹è½½å‡ºé”™ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(delay)
                continue
            raise
    return None

# ä¸»æµç¨‹
def main():
    # è®¾ç½®ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, cleanup_handler)
    signal.signal(signal.SIGTERM, cleanup_handler)
    
    # åˆå§‹åŒ–æ˜¾ç¤ºç®¡ç†å™¨
    print("åˆå§‹åŒ–æ˜¾ç¤ºè®¾å¤‡...")
    print("æ­£åœ¨åˆå§‹åŒ–OLED...")
    oled_display = DisplayManager("OLED")
    oled_display.show_text_oled("åˆå§‹åŒ–ä¸­...")
    
    print("æ­£åœ¨åˆå§‹åŒ–LCD (BitBangæ¨¡å¼)...")
    lcd_display = DisplayManager("LCD")
    oled_display.show_text_oled("åˆå§‹åŒ–å®Œæˆ")
    time.sleep(1)

    # ç¬¬1æ­¥ï¼šæ‹ç…§
    oled_display.show_text_oled("å‡†å¤‡æ‹ç…§...")
    run_camera_test()
    oled_display.show_text_oled("æ‹ç…§å®Œæˆ")
    time.sleep(1)

    # ç¬¬2æ­¥ï¼šè¯»å–å›¾ç‰‡ï¼Œåšè¯†åˆ«
    current_dir = os.path.dirname(os.path.abspath(__file__))
    image_path = os.path.join(current_dir, "current_image.jpg")
    oled_display.show_text_oled("æ­£åœ¨åˆ†æ\nå›¾ç‰‡...")
    
    base64_image = encode_image(image_path)
    data_url = f"data:image/jpeg;base64,{base64_image}"

    print("å‘é€ç…§ç‰‡è¯†åˆ«è¯·æ±‚...")
    # ç¬¬ä¸€è½®ï¼šå›¾ç‰‡è¯†åˆ«
    response = chat_with_gpt(
        input_content=[
            {"type": "input_text", "text": "è¯·ç®€çŸ­æè¿°è¿™å¼ ç…§ç‰‡çš„ä¸»è¦å†…å®¹ã€‚"},
            {"type": "input_image", "image_url": data_url}
        ]
    )
    description = response.output[0].content[0].text.strip()
    print("\nğŸ“· è¯†åˆ«ç»“æœï¼š", description)
    oled_display.show_text_oled("è¯†åˆ«å®Œæˆ")
    time.sleep(1)

    # ç¬¬äºŒè½®ï¼šç”Ÿæˆå²è±å§†æ€§æ ¼
    oled_display.show_text_oled("æ­£åœ¨ç”Ÿæˆ\nå²è±å§†æ€§æ ¼...")
    response = chat_with_gpt(
        system_content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§’è‰²è®¾å®šå¸ˆã€‚æ ¹æ®ç¯å¢ƒæˆ–ç‰©ä½“çš„æè¿°ï¼Œå¸®æˆ‘è®¾å®šä¸€åªå²è±å§†çš„å°æ¡£æ¡ˆï¼ŒåŒ…æ‹¬å®ƒçš„æ€§æ ¼ã€è¡¨æƒ…ã€åŠ¨ä½œç‰¹ç‚¹ç­‰ï¼Œç”¨è‹±æ–‡ç®€æ´æè¿°ï¼Œä¸è¦å¤ªé•¿ï¼Œæƒ…æ„Ÿè¦ç»†è…»ã€‚",
        input_content=f"æ ¹æ®è¿™ä¸ªæè¿°è®¾å®šä¸€åªå²è±å§†ï¼š{description}",
        previous_response_id=response.id
    )
    slime_personality_text = response.output[0].content[0].text.strip()
    oled_display.show_text_oled("æ€§æ ¼è®¾å®šå®Œæˆ")
    time.sleep(1)

    # ç¬¬ä¸‰è½®ï¼šç”Ÿæˆæ‰“æ‹›å‘¼
    oled_display.show_text_oled("æ­£åœ¨æƒ³æ‰“æ‹›å‘¼\nçš„è¯...")
    response = chat_with_gpt(
        system_content="ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ã€‚è¯·æ ¹æ®ç»™å®šçš„æ€§æ ¼æè¿°è¯´è¯ï¼Œä¸­æ–‡ï¼Œä¸è¶…è¿‡15ä¸ªå­—ã€‚",
        input_content=f"æ ¹æ®è¿™ä¸ªæ€§æ ¼æè¿°ç”Ÿæˆæ‰“æ‹›å‘¼ç”¨è¯­ï¼š{slime_personality_text}",
        previous_response_id=response.id
    )
    greeting_text = response.output[0].content[0].text.strip()
    print("\nğŸ‘‹ å²è±å§†æ‰“æ‹›å‘¼ï¼š", greeting_text)

    # åœ¨OLEDä¸Šæ˜¾ç¤ºæ‰“æ‹›å‘¼æ–‡æœ¬
    oled_display.show_text_oled(greeting_text)
    time.sleep(3)

    # ç”Ÿæˆå²è±å§†å›¾ç‰‡
    oled_display.show_text_oled("æ­£åœ¨ç»˜åˆ¶\nå²è±å§†...")
    slime_prompt = f"""
    Create a charming pixel art slime character. {slime_personality_text}
    
    Design the slime as a simple blob shape with large eyes and a tiny mouth, showing its unique personality traits.
    
    Render in Game Boy style monochrome pixel art using only black and white pixels.
    """
    print("\nğŸ¨ ç”Ÿæˆå²è±å§†æç¤ºè¯ï¼š", slime_prompt)

    # ç¬¬4æ­¥ï¼šç”¨Replicateç”Ÿæˆå²è±å§†å›¾ç‰‡
    print("\nğŸ–Œï¸ å¼€å§‹ç»˜åˆ¶å²è±å§†å›¾ç‰‡ï¼ˆReplicateç”Ÿæˆï¼‰...")
    output = replicate_client.run(
        "black-forest-labs/flux-schnell",
        input={
            "prompt": slime_prompt,
            "prompt_upsampling": True,
            "width": 320,        # åŒ¹é…LCDå®½åº¦
            "height": 240,       # åŒ¹é…LCDé«˜åº¦
            "num_inference_steps": 4  # flux-schnellæ¨¡å‹æœ€å¤§æ”¯æŒ4æ­¥
        }
    )

    # ä»è¿”å›çš„URLä¸‹è½½å›¾ç‰‡
    if isinstance(output, list) and len(output) > 0:
        image_url = output[0]
        print(f"æ­£åœ¨ä¸‹è½½å›¾ç‰‡: {image_url}")
        oled_display.show_text_oled("æ­£åœ¨ä¸‹è½½\nå²è±å§†å›¾ç‰‡...")
        
        try:
            img_response = download_with_retry(image_url)
            if img_response:
                output_path = os.path.join(current_dir, "new_slime.png")
                with open(output_path, "wb") as f:
                    f.write(img_response.content)
                print(f"\nâœ… æ–°å²è±å§†ç»˜åˆ¶å®Œæˆï¼Œå·²ä¿å­˜ä¸º: {output_path}")
                oled_display.show_text_oled("å²è±å§†\nç»˜åˆ¶å®Œæˆï¼")
                time.sleep(1)
            else:
                print("ä¸‹è½½å›¾ç‰‡å¤±è´¥")
                oled_display.show_text_oled("å›¾ç‰‡ä¸‹è½½å¤±è´¥")
        except Exception as e:
            print(f"ä¸‹è½½å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            oled_display.show_text_oled("å›¾ç‰‡ä¸‹è½½å¤±è´¥")
    else:
        print("ç”Ÿæˆå›¾ç‰‡å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„URL")
        oled_display.show_text_oled("å›¾ç‰‡ç”Ÿæˆå¤±è´¥")

    # ç¬¬äº”æ­¥ï¼šåœ¨LCDä¸Šæ˜¾ç¤ºå›¾ç‰‡å¹¶å¤„ç†è¯­éŸ³è¾“å…¥
    try:
        print("\nğŸ“º æ­£åœ¨æ˜¾ç¤ºå²è±å§†å›¾ç‰‡...")
        lcd_display.show_image(output_path)
        
        # æ˜¾ç¤ºè¯­éŸ³è¾“å…¥æç¤º
        print("\nğŸ¤ å‡†å¤‡å½•éŸ³...")
        oled_display.show_text_oled("è¯·è¯´è¯...\n(5ç§’)")
        time.sleep(1)  # ç»™ç”¨æˆ·ä¸€ç‚¹å‡†å¤‡æ—¶é—´
        
        # è¯­éŸ³è¾“å…¥
        stt = SpeechToText()
        user_input = stt.record_and_transcribe(duration=5)
        print(f"\nğŸ‘‚ ä½ è¯´çš„æ˜¯: {user_input}")
        
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
        oled_display.show_text_oled(f"è¯†åˆ«ç»“æœ:\n{user_input}")
        time.sleep(3)  # æ˜¾ç¤º3ç§’è¯†åˆ«ç»“æœ
        
        # æ˜¾ç¤ºæ€è€ƒæç¤º
        oled_display.show_text_oled("æ€è€ƒä¸­...")
        
        # ç¬¬å››è½®ï¼šç”Ÿæˆå²è±å§†çš„å›ç­”
        response = chat_with_gpt(
            system_content="ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„å²è±å§†ã€‚è¯·æ ¹æ®ç»™å®šçš„æ€§æ ¼æè¿°è¯´è¯ï¼Œä¸è¶…è¿‡15ä¸ªå­—ã€‚",
            input_content=f"æ€§æ ¼æè¿°ï¼š{slime_personality_text}\nç”¨æˆ·è¯´ï¼š{user_input}ï¼Œè¯·ä½ æ ¹æ®è¿™ä¸ªç»™å›ç­”ï¼Œå¹¶ç»™ä»–ä¸€ä¸ªæ¼‚æµçš„æç¤ºï¼ˆä¸‹ä¸€æ­¥å»å‘å“ªé‡Œï¼‰",
            previous_response_id=response.id
        )
        
        response_text = response.output[0].content[0].text.strip()
        print(f"\nğŸ‘‹ å²è±å§†å›ç­”ï¼š{response_text}")
        
        # æ˜¾ç¤ºå²è±å§†çš„å›ç­”
        oled_display.show_text_oled(response_text)
        time.sleep(3)
        
        time.sleep(60)
        lcd_display.clear()
    except Exception as e:
        print(f"æ˜¾ç¤ºå›¾ç‰‡æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    main()